{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#label-pipeline","title":"Label Pipeline","text":"<p>This repository hosts the necessary AWS Lambda scripts to facilitate an automated audio labeling pipeline. The main components of the pipeline includes:</p> Component Description Audio Transcription using AWS Transcribe Transcribe incoming audios stored in S3 using AWS Transcribe. After transcribing, align audios based on ground truth values and save annotations. Audio Splitting Based on audio alignment transcriptions, segment audios and split into different files before saving back to S3. Audio Adult/Child Classifier Classify incoming audios stored in S3 as either adult, or child audios. Integration with AirTable Dashboards Export AirTable audio annotations (transcript and labels) to S3 by moving files according to their labels. Audio Recording Logger Logs daily audio recording data from S3 Inventory to AirTable. <p>For more details of each component, please check each subdirectory's README file.</p>"},{"location":"#pipeline-overview","title":"Pipeline Overview","text":"<p>The high-level overview of this pipeline is shown below.</p> <p></p>"},{"location":"#installation","title":"Installation","text":"<pre><code>git clone https://github.com/bookbot-kids/label-pipeline.git\ncd label-pipeline\npip install -r requirements.txt\n</code></pre>"},{"location":"#references","title":"References","text":"<pre><code>@misc{label-studio-no-date,\nauthor = {{Label Studio}},\ntitle = {{Improve Audio Transcriptions with Label Studio}},\nurl = {https://labelstud.io/blog/Improve-Audio-Transcriptions-with-Label-Studio.html},\n}\n</code></pre>"},{"location":"#contributors","title":"Contributors","text":""},{"location":"contributing/","title":"Contributing","text":"<p>Hi there! Thanks for taking your time to contribute!</p> <p>We welcome everyone to contribute and we value each contribution, even the smallest ones! We want to make contributing to this project as easy and transparent as possible, whether it's:</p> <ul> <li>Reporting a bug</li> <li>Discussing the current state of the code</li> <li>Submitting a fix</li> <li>Proposing new features</li> <li>Becoming a maintainer</li> </ul>"},{"location":"contributing/#code-of-conduct","title":"Code of Conduct","text":"<p>Please be mindful to respect our Code of Conduct.</p>"},{"location":"contributing/#we-develop-with-github","title":"We Develop with Github","text":"<p>We use github to host code, to track issues and feature requests, as well as accept pull requests.</p>"},{"location":"contributing/#we-use-github-so-all-code-changes-happen-through-pull-requests","title":"We Use Github, So All Code Changes Happen Through Pull Requests","text":"<p>Pull requests are the best way to propose changes to the codebase. We actively welcome your pull requests:</p> <ol> <li>Fork the repo and create your branch from <code>main</code>.</li> <li>If you've added code that should be tested, add tests.</li> <li>If you've changed APIs, update the documentation.</li> <li>Ensure the test suite passes.</li> <li>Make sure your code lints.</li> <li>Issue that pull request!</li> </ol>"},{"location":"contributing/#any-contributions-you-make-will-be-under-the-apache-20-license","title":"Any contributions you make will be under the Apache 2.0 License","text":"<p>In short, when you submit code changes, your submissions are understood to be under the same Apache 2.0 License that covers the project. Feel free to contact the maintainers if that's a concern.</p>"},{"location":"contributing/#report-bugs-using-githubs-issues","title":"Report bugs using Github's issues","text":"<p>We use GitHub issues to track public bugs. Report a bug by opening a new issue.</p>"},{"location":"contributing/#write-bug-reports-with-detail-background-and-sample-code","title":"Write bug reports with detail, background, and sample code","text":"<p>This is an example of a good and thorough bug report.</p> <p>Great Bug Reports tend to have:</p> <ul> <li>A quick summary and/or background</li> <li>Steps to reproduce</li> <li>Be specific!</li> <li>Give sample code if you can.</li> <li>What you expected would happen</li> <li>What actually happens</li> <li>Notes (possibly including why you think this might be happening, or stuff you tried that didn't work)</li> </ul>"},{"location":"contributing/#license","title":"License","text":"<p>By contributing, you agree that your contributions will be licensed under its Apache 2.0 License.</p>"},{"location":"contributing/#references","title":"References","text":"<p>This document was adapted from the open-source contribution guidelines for Facebook's Draft</p>"},{"location":"reference/airtable_apply_annotations/airtable_s3_integration/","title":"AirTable S3 Integration","text":""},{"location":"reference/airtable_apply_annotations/airtable_s3_integration/#airtable_apply_annotations.airtable_s3_integration","title":"<code>airtable_apply_annotations.airtable_s3_integration</code>","text":""},{"location":"reference/airtable_apply_annotations/airtable_s3_integration/#airtable_apply_annotations.airtable_s3_integration.AirTableS3Integration","title":"<code>AirTableS3Integration</code>","text":"Source code in <code>src/airtable_apply_annotations/airtable_s3_integration.py</code> <pre><code>class AirTableS3Integration:\ndef __init__(self, airtable_url: str, filter_formula: str, headers: Dict[str, str]):\n\"\"\"Constructor for the `AirTableS3Integration` class.\n        Args:\n            airtable_url (str): URL endpoint to AirTable table.\n            filter_formula (str): Additional GET URL filter formula parameter.\n            headers (Dict[str, str]): API Header containing authorization.\n        \"\"\"\nself.airtable_url = airtable_url\nself.filter_formula = filter_formula\nself.headers = headers\nself.bucket = BUCKET\nself.extensions = EXTENSIONS\ndef process_table_data(self):\n\"\"\"\n        Gets AirTable data and applies annotation changes to S3 and finalizes the\n        record.\n        \"\"\"\nrecords, offset = [], 0\nwhile True:\ntry:\nresponse = requests.get(\nf\"{self.airtable_url}&amp;{self.filter_formula}\",\nparams={\"offset\": offset},\nheaders=self.headers,\n)\nexcept Exception as exc:\nprint(exc)\nelse:\nif response.ok:\nresponse = response.json()\nrecords += response[\"records\"]\nif \"offset\" in response:\noffset = response[\"offset\"]\nelse:\nbreak\nelse:\nprint(\"Failed to get data from AirTable\")\n# batch size: 10\nfor i in range(0, len(records), 10):\nbatch = records[i : i + 10]\nfor record in batch:\nself._apply_annotation_changes_s3(record)\nself._patch_record(self._finalize_records(batch))\ndef _patch_record(self, payload: str):\n\"\"\"Patches `payload` to `self.airtable_url` with authorized `self.headers`.\n        Args:\n            payload (str): Record payload.\n        \"\"\"\ntry:\nresponse = requests.patch(\nself.airtable_url, headers=self.headers, data=payload\n)\nexcept Exception as exc:\nprint(exc)\nelse:\nif response.ok:\nreturn\nelse:\nprint(f\"Failed to patch {payload}\")\ndef _apply_annotation_changes_s3(self, record: Dict[str, Any]):\n\"\"\"Applies changes in an S3 directory based on an AirTable `record`'s annotation\n        verdict.\n        Args:\n            record (Dict[str, Any]): An AirTable record/row.\n        \"\"\"\npass\ndef _finalize_records(self, records: List[Dict[str, Any]]) -&gt; str:\n\"\"\"Finalizes records by marking \"AWS\" column as `True`.\n        Args:\n            records (List[Dict[str, Any]]): AirTable records.\n        Returns:\n            str: Finalized record payload.\n        \"\"\"\npass\n</code></pre>"},{"location":"reference/airtable_apply_annotations/airtable_s3_integration/#airtable_apply_annotations.airtable_s3_integration.AirTableS3Integration.__init__","title":"<code>__init__(airtable_url, filter_formula, headers)</code>","text":"<p>Constructor for the <code>AirTableS3Integration</code> class.</p> <p>Parameters:</p> Name Type Description Default <code>airtable_url</code> <code>str</code> <p>URL endpoint to AirTable table.</p> required <code>filter_formula</code> <code>str</code> <p>Additional GET URL filter formula parameter.</p> required <code>headers</code> <code>Dict[str, str]</code> <p>API Header containing authorization.</p> required Source code in <code>src/airtable_apply_annotations/airtable_s3_integration.py</code> <pre><code>def __init__(self, airtable_url: str, filter_formula: str, headers: Dict[str, str]):\n\"\"\"Constructor for the `AirTableS3Integration` class.\n    Args:\n        airtable_url (str): URL endpoint to AirTable table.\n        filter_formula (str): Additional GET URL filter formula parameter.\n        headers (Dict[str, str]): API Header containing authorization.\n    \"\"\"\nself.airtable_url = airtable_url\nself.filter_formula = filter_formula\nself.headers = headers\nself.bucket = BUCKET\nself.extensions = EXTENSIONS\n</code></pre>"},{"location":"reference/airtable_apply_annotations/airtable_s3_integration/#airtable_apply_annotations.airtable_s3_integration.AirTableS3Integration.process_table_data","title":"<code>process_table_data()</code>","text":"<p>Gets AirTable data and applies annotation changes to S3 and finalizes the record.</p> Source code in <code>src/airtable_apply_annotations/airtable_s3_integration.py</code> <pre><code>def process_table_data(self):\n\"\"\"\n    Gets AirTable data and applies annotation changes to S3 and finalizes the\n    record.\n    \"\"\"\nrecords, offset = [], 0\nwhile True:\ntry:\nresponse = requests.get(\nf\"{self.airtable_url}&amp;{self.filter_formula}\",\nparams={\"offset\": offset},\nheaders=self.headers,\n)\nexcept Exception as exc:\nprint(exc)\nelse:\nif response.ok:\nresponse = response.json()\nrecords += response[\"records\"]\nif \"offset\" in response:\noffset = response[\"offset\"]\nelse:\nbreak\nelse:\nprint(\"Failed to get data from AirTable\")\n# batch size: 10\nfor i in range(0, len(records), 10):\nbatch = records[i : i + 10]\nfor record in batch:\nself._apply_annotation_changes_s3(record)\nself._patch_record(self._finalize_records(batch))\n</code></pre>"},{"location":"reference/airtable_apply_annotations/audio_dashboard_table/","title":"Audio Dashboard Table","text":""},{"location":"reference/airtable_apply_annotations/audio_dashboard_table/#airtable_apply_annotations.audio_dashboard_table","title":"<code>airtable_apply_annotations.audio_dashboard_table</code>","text":""},{"location":"reference/airtable_apply_annotations/audio_dashboard_table/#airtable_apply_annotations.audio_dashboard_table.AudioDashboardTable","title":"<code>AudioDashboardTable</code>","text":"<p>             Bases: <code>AirTableS3Integration</code></p> Source code in <code>src/airtable_apply_annotations/audio_dashboard_table.py</code> <pre><code>class AudioDashboardTable(AirTableS3Integration):\ndef __init__(self, airtable_url: str, filter_formula: str, headers: Dict[str, str]):\n\"\"\"Constructor for the `AudioDashboardTable` class.\n        Args:\n            airtable_url (str): URL endpoint to AirTable table.\n            filter_formula (str): Additional GET URL filter formula parameter.\n            headers (Dict[str, str]): API Header containing authorization.\n        \"\"\"\nsuper().__init__(airtable_url, filter_formula, headers)\ndef _apply_annotation_changes_s3(self, record: Dict[str, Any]):\n\"\"\"Applies changes in an S3 directory based on an AirTable `record`'s category verdict.\n        Args:\n            record (Dict[str, Any]): An AirTable record/row.\n        \"\"\"\nfields = record[\"fields\"]\njob_name, language = fields[\"Job Name\"], fields[\"Language\"]\ncategory, transcript = fields[\"Category\"].lower(), fields[\"Transcript\"]\naudio_filename = fields[\"Audio\"][0][\"filename\"]\nsource_path = f\"categorisation/raw/{language}\"\nsave_path = f\"categorisation/{category}/{language}\"\nif category == \"delete\":\ndelete_file(self.bucket, audio_filename, source_path)\nelse:\nmove_file(self.bucket, audio_filename, source_path, save_path)\nwrite_file(self.bucket, transcript, save_path, f\"{job_name}.txt\")\ndef _finalize_records(self, records: List[Dict[str, Any]]) -&gt; str:\n\"\"\"Finalizes audio records by marking \"AWS\" column as `True`.\n        Args:\n            records (List[Dict[str, Any]]): AirTable records.\n        Returns:\n            str: Finalized record payload.\n        \"\"\"\npayload = json.dumps(\n{\n\"records\": [\n{\"id\": record[\"id\"], \"fields\": {\"AWS\": True}} for record in records\n]\n}\n)\nreturn payload\n</code></pre>"},{"location":"reference/airtable_apply_annotations/audio_dashboard_table/#airtable_apply_annotations.audio_dashboard_table.AudioDashboardTable.__init__","title":"<code>__init__(airtable_url, filter_formula, headers)</code>","text":"<p>Constructor for the <code>AudioDashboardTable</code> class.</p> <p>Parameters:</p> Name Type Description Default <code>airtable_url</code> <code>str</code> <p>URL endpoint to AirTable table.</p> required <code>filter_formula</code> <code>str</code> <p>Additional GET URL filter formula parameter.</p> required <code>headers</code> <code>Dict[str, str]</code> <p>API Header containing authorization.</p> required Source code in <code>src/airtable_apply_annotations/audio_dashboard_table.py</code> <pre><code>def __init__(self, airtable_url: str, filter_formula: str, headers: Dict[str, str]):\n\"\"\"Constructor for the `AudioDashboardTable` class.\n    Args:\n        airtable_url (str): URL endpoint to AirTable table.\n        filter_formula (str): Additional GET URL filter formula parameter.\n        headers (Dict[str, str]): API Header containing authorization.\n    \"\"\"\nsuper().__init__(airtable_url, filter_formula, headers)\n</code></pre>"},{"location":"reference/airtable_apply_annotations/disfluency_table/","title":"Disfluency Table","text":""},{"location":"reference/airtable_apply_annotations/disfluency_table/#airtable_apply_annotations.disfluency_table","title":"<code>airtable_apply_annotations.disfluency_table</code>","text":""},{"location":"reference/airtable_apply_annotations/disfluency_table/#airtable_apply_annotations.disfluency_table.DisfluencyTable","title":"<code>DisfluencyTable</code>","text":"<p>             Bases: <code>AirTableS3Integration</code></p> Source code in <code>src/airtable_apply_annotations/disfluency_table.py</code> <pre><code>class DisfluencyTable(AirTableS3Integration):\ndef __init__(self, airtable_url: str, filter_formula: str, headers: Dict[str, str]):\n\"\"\"Constructor for the `DisfluencyTable` class.\n        Args:\n            airtable_url (str): URL endpoint to AirTable table.\n            filter_formula (str): Additional GET URL filter formula parameter.\n            headers (Dict[str, str]): API Header containing authorization.\n        \"\"\"\nsuper().__init__(airtable_url, filter_formula, headers)\ndef _apply_annotation_changes_s3(self, record: Dict[str, Any]):\n\"\"\"Applies changes in an S3 directory based on an AirTable `record`'s disfluency\n        verdict.\n        Args:\n            record (Dict[str, Any]): An AirTable record/row.\n        \"\"\"\ndef classify_mispronunciation(transcript, ground_truth, language):\n_preprocess_sequence = (\nlambda sequence: sequence.replace(\"-\", \" \")\n.translate(str.maketrans(\"\", \"\", string.punctuation))\n.lower()\n.strip()\n)\ntranscript = _preprocess_sequence(transcript).split()\nground_truth = _preprocess_sequence(ground_truth).split()\nhomophones = HOMOPHONES[language] if language in HOMOPHONES else None\nmispronunciation = detect_mispronunciation(\nground_truth, transcript, homophones\n)\nreturn mispronunciation\nfields = record[\"fields\"]\njob_name, language = fields[\"Job Name\"], fields[\"Language\"]\nground_truth, transcript = fields[\"Ground Truth\"], fields[\"Transcript\"]\naudio_filename = fields[\"Audio\"][0][\"filename\"]\ndelete = fields[\"Delete?\"] if \"Delete?\" in fields else False\n# recalculate disfluency\ndisfluency = classify_mispronunciation(\ntranscript, ground_truth, language.split(\"-\")[0]\n)\nfields[\"Disfluency\"] = disfluency\nsource_path = f\"mispronunciations/raw/{language}\"\nsave_path = f\"mispronunciations/{disfluency.lower()}/{language}\"\n# if manually marked to delete or if no disfluency is detected\nif delete or disfluency == \"DELETE\":\ndelete_file(self.bucket, audio_filename, source_path)\nelse:\nmove_file(self.bucket, audio_filename, source_path, save_path)\nwrite_file(self.bucket, transcript, save_path, f\"{job_name}.txt\")\ndef _finalize_records(self, records: List[Dict[str, Any]]) -&gt; str:\n\"\"\"Finalizes disfluency records by marking \"AWS\" column as `True` and updating\n        disfluency.\n        Args:\n            records (List[Dict[str, Any]]): AirTable records.\n        Returns:\n            str: Finalized record payload.\n        \"\"\"\npayload = json.dumps(\n{\n\"records\": [\n{\n\"id\": record[\"id\"],\n\"fields\": {\n\"Disfluency\": record[\"fields\"][\"Disfluency\"],\n\"AWS\": True,\n},\n}\nfor record in records\n]\n}\n)\nreturn payload\n</code></pre>"},{"location":"reference/airtable_apply_annotations/disfluency_table/#airtable_apply_annotations.disfluency_table.DisfluencyTable.__init__","title":"<code>__init__(airtable_url, filter_formula, headers)</code>","text":"<p>Constructor for the <code>DisfluencyTable</code> class.</p> <p>Parameters:</p> Name Type Description Default <code>airtable_url</code> <code>str</code> <p>URL endpoint to AirTable table.</p> required <code>filter_formula</code> <code>str</code> <p>Additional GET URL filter formula parameter.</p> required <code>headers</code> <code>Dict[str, str]</code> <p>API Header containing authorization.</p> required Source code in <code>src/airtable_apply_annotations/disfluency_table.py</code> <pre><code>def __init__(self, airtable_url: str, filter_formula: str, headers: Dict[str, str]):\n\"\"\"Constructor for the `DisfluencyTable` class.\n    Args:\n        airtable_url (str): URL endpoint to AirTable table.\n        filter_formula (str): Additional GET URL filter formula parameter.\n        headers (Dict[str, str]): API Header containing authorization.\n    \"\"\"\nsuper().__init__(airtable_url, filter_formula, headers)\n</code></pre>"},{"location":"reference/airtable_apply_annotations/homophones/","title":"Homophones","text":""},{"location":"reference/airtable_apply_annotations/homophones/#airtable_apply_annotations.homophones","title":"<code>airtable_apply_annotations.homophones</code>","text":""},{"location":"reference/airtable_apply_annotations/homophones/#airtable_apply_annotations.homophones.create_convert","title":"<code>create_convert(*families)</code>","text":"<p>Return a converter function that converts a list to the same list with only main words</p> <p>Parameters:</p> Name Type Description Default <code>*families</code> <code>List[Set[str]]</code> <p>List of homophone families.</p> <code>()</code> <p>Returns:</p> Type Description <code>List[List[str]]</code> <p>List[List[str]]: True if all paths exist in <code>files</code></p> Source code in <code>src/airtable_apply_annotations/homophones.py</code> <pre><code>def create_convert(*families: List[Set[str]]) -&gt; List[List[str]]:\n\"\"\"Return a converter function that converts a list to the same list with only main\n    words\n    Args:\n        *families (List[Set[str]]): List of homophone families.\n    Returns:\n        List[List[str]]: True if all paths exist in `files`\n    \"\"\"\nd = {w: main for main, *alternatives in map(list, families) for w in alternatives}\nreturn lambda L: [d.get(w, w) for w in L]\n</code></pre>"},{"location":"reference/airtable_apply_annotations/homophones/#airtable_apply_annotations.homophones.match_sequence","title":"<code>match_sequence(list1, list2, homophones)</code>","text":"<p>Finds index of overlaps between two lists given a homophone mapping.</p> <p>Parameters:</p> Name Type Description Default <code>list1</code> <code>List[str]</code> <p>List of words in a sequence.</p> required <code>list2</code> <code>List[str]</code> <p>List of words in another sequence for matching/comparison.</p> required <code>homophones</code> <code>List[Set[str]]</code> <p>List of homophone families.</p> required <p>Returns:</p> Type Description <code>Tuple[List[int], List[int], List[Tuple[str, int, int, int, int]]]</code> <p>Tuple[List[int], List[int], List[Tuple[str, int, int, int, int]]]: Pair of lists containing list of indices of overlap.</p> Source code in <code>src/airtable_apply_annotations/homophones.py</code> <pre><code>def match_sequence(\nlist1: List[str], list2: List[str], homophones: List[Set[str]]\n) -&gt; Tuple[List[int], List[int], List[Tuple[str, int, int, int, int]]]:\n\"\"\"Finds index of overlaps between two lists given a homophone mapping.\n    Args:\n        list1 (List[str]): List of words in a sequence.\n        list2 (List[str]): List of words in another sequence for matching/comparison.\n        homophones (List[Set[str]]): List of homophone families.\n    Returns:\n        Tuple[List[int], List[int], List[Tuple[str, int, int, int, int]]]:\n            Pair of lists containing list of indices of overlap.\n    \"\"\"\nconvert = create_convert(*homophones)\noutput1, output2 = [], []\ns = SequenceMatcher(None, convert(list1), convert(list2))\nopcodes = s.get_opcodes()\nfor block in s.get_matching_blocks():\nfor i in range(block.size):\noutput1.append(block.a + i)\noutput2.append(block.b + i)\nassert len(output1) == len(output2)\nreturn output1, output2, opcodes\n</code></pre>"},{"location":"reference/airtable_apply_annotations/lambda_function/","title":"AWS Lambda Event Handler","text":""},{"location":"reference/airtable_apply_annotations/lambda_function/#airtable_apply_annotations.lambda_function","title":"<code>airtable_apply_annotations.lambda_function</code>","text":""},{"location":"reference/airtable_apply_annotations/lambda_function/#airtable_apply_annotations.lambda_function.lambda_handler","title":"<code>lambda_handler(event, context)</code>","text":"<p>Event listener for S3 event and calls the daily logger function.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>AWS Event</code> <p>A JSON-formatted document that contains data for a Lambda                function to process.</p> required <code>context</code> <code>AWS Context</code> <p>An object that provides methods and properties that                    provide information about the invocation, function,                    and runtime environment.</p> required Source code in <code>src/airtable_apply_annotations/lambda_function.py</code> <pre><code>def lambda_handler(event, context):\n\"\"\"Event listener for S3 event and calls the daily logger function.\n    Args:\n        event (AWS Event): A JSON-formatted document that contains data for a Lambda\n                           function to process.\n        context (AWS Context): An object that provides methods and properties that\n                               provide information about the invocation, function,\n                               and runtime environment.\n    \"\"\"\nmain()\n</code></pre>"},{"location":"reference/airtable_apply_annotations/mispronunciation/","title":"Mispronunciation","text":""},{"location":"reference/airtable_apply_annotations/mispronunciation/#airtable_apply_annotations.mispronunciation","title":"<code>airtable_apply_annotations.mispronunciation</code>","text":""},{"location":"reference/airtable_apply_annotations/mispronunciation/#airtable_apply_annotations.mispronunciation.detect_mispronunciation","title":"<code>detect_mispronunciation(ground_truth, transcript, homophones=None)</code>","text":"<p>Detects if the pair of ground truth and transcript is considered as a mispronunciation.</p> <p>We define a mispronunciation to be either an addition (A) / substitution (S). Ignores deletion (D), 100% match (M) and single-word GT (X), returning <code>None</code>. Also handles homophones given a pre-defined list.</p> <p>Parameters:</p> Name Type Description Default <code>ground_truth</code> <code>List[str]</code> <p>List of ground truth words.</p> required <code>transcript</code> <code>List[str]</code> <p>List of transcript words.</p> required <code>homophones</code> <code>List[Set[str]]</code> <p>List of homophone families. Defaults to</p> <code>None</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Type of mispronunciation present. Otherwise, None.</p> Source code in <code>src/airtable_apply_annotations/mispronunciation.py</code> <pre><code>def detect_mispronunciation(\nground_truth: List[str], transcript: List[str], homophones: List[Set[str]] = None\n) -&gt; str:\n\"\"\"Detects if the pair of ground truth and transcript is considered as a\n    mispronunciation.\n    We define a mispronunciation to be either an addition (A) / substitution (S).\n    Ignores deletion (D), 100% match (M) and single-word GT (X), returning `None`.\n    Also handles homophones given a pre-defined list.\n    Args:\n        ground_truth (List[str]): List of ground truth words.\n        transcript (List[str]): List of transcript words.\n        homophones (List[Set[str]], optional): List of homophone families. Defaults to\n        None.\n    Returns:\n        str: Type of mispronunciation present. Otherwise, None.\n    \"\"\"\nif homophones is None:\nhomophones = HOMOPHONES[\"en\"]\nif len(ground_truth) == 1 or len(transcript) == 0:\nreturn \"DELETE\"  # single word or filler-only transcript\ntsc_idx = set(range(len(transcript)))\ngt_idx = set(range(len(ground_truth)))\naligned_tsc, aligned_gt, _ = match_sequence(transcript, ground_truth, homophones)\nif len(aligned_tsc) == 0 and len(aligned_gt) == 0:\nreturn \"DELETE\"  # zero matches/alignments, pretty much random\ntsc_diff = tsc_idx.difference(aligned_tsc)\ngt_diff = gt_idx.difference(aligned_gt)\nif len(gt_diff) == 0 and len(tsc_diff) == 0:\nreturn \"DELETE\"  # 100% match\nelif len(gt_diff) &gt; 0 and len(tsc_diff) == 0:\nreturn \"DELETE\"  # deletion only\nelif len(gt_diff) == 0 and len(tsc_diff) &gt; 0:\nreturn \"ADDITION\"\nelif len(tsc_diff) == len(gt_diff) and tsc_diff == gt_diff:\nreturn \"SUBSTITUTION\"\nelif len(tsc_diff) &gt;= len(gt_diff):\nreturn \"ADDITION_SUBSTITUTION\"\nelse:\nreturn \"DELETE\"\n</code></pre>"},{"location":"reference/airtable_apply_annotations/s3_utils/","title":"AWS S3 Utilities","text":""},{"location":"reference/airtable_apply_annotations/s3_utils/#airtable_apply_annotations.s3_utils","title":"<code>airtable_apply_annotations.s3_utils</code>","text":""},{"location":"reference/airtable_apply_annotations/s3_utils/#airtable_apply_annotations.s3_utils.bulk_s3_actions","title":"<code>bulk_s3_actions(action, bucket, files, sources, targets=None)</code>","text":"<p>Applies a bulk S3 CRUD action for all <code>files</code> in <code>sources</code> and optionally, <code>targets</code>.</p> <p>Parameters:</p> Name Type Description Default <code>action</code> <code>Callable</code> <p>Function calling an S3 CRUD operation.</p> required <code>bucket</code> <code>str</code> <p>S3 bucket name.</p> required <code>files</code> <code>List[str]</code> <p>List of files in <code>bucket</code>/<code>sources</code></p> required <code>sources</code> <code>List[str]</code> <p>Source folders in <code>bucket</code>.</p> required <code>targets</code> <code>List[str]</code> <p>Target folders in <code>bucket</code>. Defaults to None.</p> <code>None</code> Source code in <code>src/airtable_apply_annotations/s3_utils.py</code> <pre><code>def bulk_s3_actions(\naction: Callable,\nbucket: str,\nfiles: List[str],\nsources: List[str],\ntargets: List[str] = None,\n):\n\"\"\"Applies a bulk S3 CRUD action for all `files` in `sources` and optionally, `targets`.\n    Args:\n        action (Callable): Function calling an S3 CRUD operation.\n        bucket (str): S3 bucket name.\n        files (List[str]): List of files in `bucket`/`sources`\n        sources (List[str]): Source folders in `bucket`.\n        targets (List[str], optional): Target folders in `bucket`. Defaults to None.\n    \"\"\"\nif targets:\nassert len(sources) == len(targets)\nfor source, target in zip(sources, targets):\nfor file in files:\naction(bucket=bucket, file=file, source=source, destination=target)\nelse:\nfor source in sources:\nfor file in files:\naction(bucket=bucket, file=file, source=source)\n</code></pre>"},{"location":"reference/airtable_apply_annotations/s3_utils/#airtable_apply_annotations.s3_utils.copy_file","title":"<code>copy_file(bucket, file, source, destination)</code>","text":"<p>Copy <code>file</code> in <code>bucket</code> from <code>source</code> to <code>destination</code> folder.</p> <p>Parameters:</p> Name Type Description Default <code>bucket</code> <code>str</code> <p>S3 bucket name.</p> required <code>file</code> <code>str</code> <p>Name of file to be copied (without full-path).</p> required <code>source</code> <code>str</code> <p>Source folder in S3 bucket.</p> required <code>destination</code> <code>str</code> <p>Destination folder in S3 bucket.</p> required Source code in <code>src/airtable_apply_annotations/s3_utils.py</code> <pre><code>def copy_file(bucket: str, file: str, source: str, destination: str):\n\"\"\"Copy `file` in `bucket` from `source` to `destination` folder.\n    Args:\n        bucket (str): S3 bucket name.\n        file (str): Name of file to be copied (without full-path).\n        source (str): Source folder in S3 bucket.\n        destination (str): Destination folder in S3 bucket.\n    \"\"\"\ntry:\ns3_resource.Object(bucket, f\"{destination}/{file}\").copy_from(\nCopySource=f\"{bucket}/{source}/{file}\"\n)\nprint(\nf\"Copied file from {bucket}/{source}/{file} to\",\nf\"{bucket}/{destination}/{file}\",\n)\nexcept ClientError:\nreturn\n</code></pre>"},{"location":"reference/airtable_apply_annotations/s3_utils/#airtable_apply_annotations.s3_utils.delete_file","title":"<code>delete_file(bucket, file, source)</code>","text":"<p>Delete <code>file</code> in <code>bucket</code> from <code>source</code> folder.</p> <p>Parameters:</p> Name Type Description Default <code>bucket</code> <code>str</code> <p>S3 bucket name.</p> required <code>file</code> <code>str</code> <p>Name of file to be deleted (without full-path).</p> required <code>source</code> <code>str</code> <p>Source folder in S3 bucket.</p> required Source code in <code>src/airtable_apply_annotations/s3_utils.py</code> <pre><code>def delete_file(bucket: str, file: str, source: str):\n\"\"\"Delete `file` in `bucket` from `source` folder.\n    Args:\n        bucket (str): S3 bucket name.\n        file (str): Name of file to be deleted (without full-path).\n        source (str): Source folder in S3 bucket.\n    \"\"\"\ntry:\ns3_resource.Object(bucket, f\"{source}/{file}\").delete()\n# print(f\"Deleted file from {bucket}/{source}/{file}\")\nexcept ClientError as exc:\nprint(f\"Failed to delete {bucket}/{source}/{file}\")\nprint(exc)\n</code></pre>"},{"location":"reference/airtable_apply_annotations/s3_utils/#airtable_apply_annotations.s3_utils.move_file","title":"<code>move_file(bucket, file, source, destination)</code>","text":"<p>Move <code>file</code> in <code>bucket</code> from <code>source</code> to <code>destination</code> folder</p> <p>Parameters:</p> Name Type Description Default <code>bucket</code> <code>str</code> <p>S3 bucket name.</p> required <code>file</code> <code>str</code> <p>Name of file to be moved (without full-path).</p> required <code>source</code> <code>str</code> <p>Source folder in S3 bucket.</p> required <code>destination</code> <code>str</code> <p>Destination folder in S3 bucket.</p> required Source code in <code>src/airtable_apply_annotations/s3_utils.py</code> <pre><code>def move_file(bucket: str, file: str, source: str, destination: str):\n\"\"\"Move `file` in `bucket` from `source` to `destination` folder\n    Args:\n        bucket (str): S3 bucket name.\n        file (str): Name of file to be moved (without full-path).\n        source (str): Source folder in S3 bucket.\n        destination (str): Destination folder in S3 bucket.\n    \"\"\"\ntry:\ns3_resource.Object(bucket, f\"{destination}/{file}\").copy_from(\nCopySource=f\"{bucket}/{source}/{file}\"\n)\ns3_resource.Object(bucket, f\"{source}/{file}\").delete()\nexcept ClientError as exc:\nprint(\nf\"Failed to move file {bucket}/{source}/{file} to\",\nf\"{bucket}/{destination}/{file}\",\n)\nprint(exc)\n</code></pre>"},{"location":"reference/airtable_apply_annotations/s3_utils/#airtable_apply_annotations.s3_utils.write_file","title":"<code>write_file(bucket, file_content, destination, save_file_name)</code>","text":"<p>Writes <code>file_content</code> to <code>save_file_name</code> to <code>bucket</code> at <code>destination</code> folder.</p> <p>Parameters:</p> Name Type Description Default <code>bucket</code> <code>str</code> <p>S3 bucket name.</p> required <code>file_content</code> <code>str</code> <p>Content of file to write.</p> required <code>destination</code> <code>str</code> <p>Destination folder in S3 bucket.</p> required <code>save_file_name</code> <code>str</code> <p>Save file name</p> required Source code in <code>src/airtable_apply_annotations/s3_utils.py</code> <pre><code>def write_file(bucket: str, file_content: str, destination: str, save_file_name: str):\n\"\"\"Writes `file_content` to `save_file_name` to `bucket` at `destination` folder.\n    Args:\n        bucket (str): S3 bucket name.\n        file_content (str): Content of file to write.\n        destination (str): Destination folder in S3 bucket.\n        save_file_name (str): Save file name\n    \"\"\"\nsave_path = f\"{destination}/{save_file_name}\"\ntry:\ns3_client.put_object(Body=file_content, Bucket=bucket, Key=save_path)\nexcept ClientError:\nreturn\n</code></pre>"},{"location":"reference/audio_classifier/lambda_function/","title":"AWS Lambda Event Handler","text":""},{"location":"reference/audio_classifier/lambda_function/#audio_classifier.lambda_function","title":"<code>audio_classifier.lambda_function</code>","text":""},{"location":"reference/audio_classifier/lambda_function/#audio_classifier.lambda_function.lambda_handler","title":"<code>lambda_handler(event, context)</code>","text":"<p>Event listener for S3 event and calls the daily logger function.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>AWS Event</code> <p>A JSON-formatted document that contains data for a Lambda function to process.</p> required <code>context</code> <code>_type_</code> <p>An object that provides methods and properties that provide information about the invocation, function, and runtime environment.</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>Failed to retrieve audio.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>String-formatted JSON object containing statusCode and prediction.</p> Source code in <code>src/audio_classifier/lambda_function.py</code> <pre><code>def lambda_handler(event, context) -&gt; str:\n\"\"\"Event listener for S3 event and calls the daily logger function.\n    Args:\n        event (AWS Event):\n            A JSON-formatted document that contains data for\n            a Lambda function to process.\n        context (_type_):\n            An object that provides methods and properties that provide information\n            about the invocation, function, and runtime environment.\n    Raises:\n        Exception: Failed to retrieve audio.\n    Returns:\n        str: String-formatted JSON object containing statusCode and prediction.\n    \"\"\"\ntry:\nif event[\"headers\"][\"Authorization\"] != os.environ[\"API_KEY\"]:\nraise Exception\naudio_url = json.loads(event[\"body\"])[\"audio_url\"]\naudio = get_audio_file(audio_url)\nlanguage = os.path.basename(os.path.dirname(audio_url)).split(\"-\")[0]\naudio_array = read_audio_as_array(audio)\nif audio_array.size == 0:\nprint(f\"Audio {audio_url} is empty.\")\nraise Exception\nexcept Exception:\nresponse = {\n\"statusCode\": 400,\n\"body\": {\"prediction\": None, \"error\": \"Failed to retrieve audio.\"},\n}\nreturn json.dumps(response)\nelse:\nprocessed_audio = preprocess(audio_array)\nif language == \"id\":\n# onnx_model_path = \"/opt/distil-wav2vec2-adult-child-id-cls-52m.quant.onnx\"\nonnx_model_path = (\n\"../../models/distil-wav2vec2-adult-child-id-cls-52m.quant.onnx\"\n)\nelse:\n# onnx_model_path = \"/opt/distil-wav2vec2-adult-child-cls-52m.quant.onnx\"\nonnx_model_path = (\n\"../../models/distil-wav2vec2-adult-child-cls-52m.quant.onnx\"\n)\nresults = predict(processed_audio, onnx_model_path)\nresponse = {\"statusCode\": 200, \"body\": results}\nreturn json.dumps(response)\n</code></pre>"},{"location":"reference/audio_classifier/lambda_function/#audio_classifier.lambda_function.predict","title":"<code>predict(audio_array, onnx_model_path)</code>","text":"<p>Makes a prediction with ONNX model given audio array.</p> <p>Parameters:</p> Name Type Description Default <code>audio_array</code> <code>np.ndarray</code> <p>Array of audio to be predicted.</p> required <code>onnx_model_path</code> <code>str</code> <p>Path to ONNX model predictor.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Prediction, either \"ADULT or \"CHILD\".</p> Source code in <code>src/audio_classifier/lambda_function.py</code> <pre><code>def predict(audio_array: np.ndarray, onnx_model_path: str) -&gt; str:\n\"\"\"Makes a prediction with ONNX model given audio array.\n    Args:\n        audio_array (np.ndarray): Array of audio to be predicted.\n        onnx_model_path (str): Path to ONNX model predictor.\n    Returns:\n        str: Prediction, either \"ADULT or \"CHILD\".\n    \"\"\"\nort_session = onnxruntime.InferenceSession(onnx_model_path)\nort_inputs = {ort_session.get_inputs()[0].name: audio_array}\nort_outs = ort_session.run(None, ort_inputs)\nlogits = ort_outs[0]\npredicted_idx = np.argmax(logits)\nid2label = {\n0: \"ADULT\",\n1: \"CHILD\",\n}\nprediction = id2label[predicted_idx]\nreturn {\"prediction\": prediction, \"logits\": logits.tolist()[0]}\n</code></pre>"},{"location":"reference/audio_classifier/lambda_function/#audio_classifier.lambda_function.preprocess","title":"<code>preprocess(audio_array)</code>","text":"<p>Truncates/pads and normalizes audio array for classification using Wav2Vec2 model.</p> <p>Parameters:</p> Name Type Description Default <code>audio_array</code> <code>np.ndarray</code> <p>Array of input audio.</p> required <p>Returns:</p> Type Description <code>np.ndarray</code> <p>np.ndarray: Pre-processed audio array ready for classifier.</p> Source code in <code>src/audio_classifier/lambda_function.py</code> <pre><code>def preprocess(audio_array: np.ndarray) -&gt; np.ndarray:\n\"\"\"Truncates/pads and normalizes audio array for classification using Wav2Vec2 model.\n    Args:\n        audio_array (np.ndarray): Array of input audio.\n    Returns:\n        np.ndarray: Pre-processed audio array ready for classifier.\n    \"\"\"\nif len(audio_array) &gt; 48_000:  # truncate\naudio_array = audio_array[:48_000]\nelse:  # pad\npad_length = 48_000 - len(audio_array)\naudio_array = np.pad(audio_array, (0, pad_length))\nnormalized_audio = np.expand_dims(\n(audio_array - audio_array.mean(axis=0) / audio_array.std(axis=0)), axis=0\n)\nassert normalized_audio.shape == (1, 48_000)\nreturn normalized_audio\n</code></pre>"},{"location":"reference/audio_classifier/lambda_function/#audio_classifier.lambda_function.read_audio_as_array","title":"<code>read_audio_as_array(audio)</code>","text":"<p>Read audio from S3 url <code>audio</code>, resample to 16KHz, and return as Numpy array.</p> <p>Parameters:</p> Name Type Description Default <code>audio</code> <code>str</code> <p>S3 audio URL.</p> required <p>Returns:</p> Type Description <code>np.ndarray</code> <p>np.ndarray: Array of audio retrieved from S3.</p> Source code in <code>src/audio_classifier/lambda_function.py</code> <pre><code>def read_audio_as_array(audio: str) -&gt; np.ndarray:\n\"\"\"Read audio from S3 url `audio`, resample to 16KHz, and return as Numpy array.\n    Args:\n        audio (str): S3 audio URL.\n    Returns:\n        np.ndarray: Array of audio retrieved from S3.\n    \"\"\"\n# stream audio into ffmpeg\nstream = ffmpeg.input(audio)\noutput = ffmpeg.output(\nstream,\n\"pipe:\",\nacodec=\"pcm_s16le\",\nformat=\"wav\",\nac=1,\nar=16_000,\n)\nstdout, _ = output.run_async(pipe_stdout=True, pipe_stderr=True).communicate()\n# skip header bytes\nstdout = stdout[stdout.find(str.encode(\"data\")) + 8 :]\n# convert bytes to numpy array\n# note: int16 because of s16le encoding used\naudio_array = np.frombuffer(stdout, np.int16).astype(np.float32)\n# normalize\naudio_array /= np.iinfo(np.int16).max\nreturn audio_array\n</code></pre>"},{"location":"reference/audio_classifier/s3_utils/","title":"AWS S3 Utilities","text":""},{"location":"reference/audio_classifier/s3_utils/#audio_classifier.s3_utils","title":"<code>audio_classifier.s3_utils</code>","text":""},{"location":"reference/audio_classifier/s3_utils/#audio_classifier.s3_utils.get_audio_file","title":"<code>get_audio_file(audio_url)</code>","text":"<p>Get audio file from AWS S3, in <code>bucket</code>.</p> <p>Parameters:</p> Name Type Description Default <code>audio_url</code> <code>str</code> <p>Audio url in S3.</p> required <p>Raises:</p> Type Description <code>exc</code> <p>Error fetching file.</p> <p>Returns:</p> Name Type Description <code>_type_</code> <p>Pre-signed URL pointing to the audio file of the JSON annotation.</p> Source code in <code>src/audio_classifier/s3_utils.py</code> <pre><code>def get_audio_file(audio_url: str):\n\"\"\"Get audio file from AWS S3, in `bucket`.\n    Args:\n        audio_url (str): Audio url in S3.\n    Raises:\n        exc: Error fetching file.\n    Returns:\n        _type_: Pre-signed URL pointing to the audio file of the JSON annotation.\n    \"\"\"\naudio_url = audio_url.replace(\"s3://\", \"\")\nbucket, key = audio_url.split(\"/\", 1)\ntry:\ns3_source_signed_url = s3_client.generate_presigned_url(\n\"get_object\",\nParams={\"Bucket\": bucket, \"Key\": key},\nExpiresIn=3600,\n)\nexcept Exception as exc:\nprint(f\"Failed to fetch key: {key}\")\nraise exc\nelse:\nreturn s3_source_signed_url\n</code></pre>"},{"location":"reference/audio_recording_logger/airtable/","title":"AirTable Interface","text":""},{"location":"reference/audio_recording_logger/airtable/#audio_recording_logger.airtable","title":"<code>audio_recording_logger.airtable</code>","text":""},{"location":"reference/audio_recording_logger/airtable/#audio_recording_logger.airtable.AirTable","title":"<code>AirTable</code>","text":"Source code in <code>src/audio_recording_logger/airtable.py</code> <pre><code>class AirTable:\ndef __init__(self, url: str) -&gt; None:\n\"\"\"Constructor for AirTable table.\n        Args:\n            url (str): URL of AirTable table.\n        \"\"\"\nself.url = url\nself.headers = {\n\"Authorization\": f\"Bearer {os.environ['AIRTABLE_API_KEY']}\",\n\"Content-Type\": \"application/json\",\n}\ndef add_records(self, records: List[Dict[str, Any]]) -&gt; bool:\n\"\"\"Add records to AirTable table.\n        Args:\n            records (List[Dict[str, Any]]): List of records in AirTable format.\n        Returns:\n            bool: Whether upload was a success.\n        \"\"\"\ntry:\nresponse = requests.post(\nself.url, headers=self.headers, data=json.dumps({\"records\": records})\n)\nexcept Exception as exc:\nprint(exc)\nreturn False\nelse:\nif response.ok:\nreturn True\nelse:\nprint(f\"Failed to patch {records}\")\nreturn False\ndef batch_add_records(self, records: List[Dict[str, Any]]) -&gt; bool:\n\"\"\"Allow batching of record addition due to 10-element limit, then push.\n        Args:\n            records (List[Dict[str, Any]]): List of records in AirTable format.\n        Returns:\n            bool: Whether upload was a success.\n        \"\"\"\nbatch_size = 10\nfor idx in range(0, len(records), batch_size):\nbatch = records[idx : idx + batch_size]\nsuccess = self.add_records(batch)\nif not success:\nreturn success\nreturn True\n</code></pre>"},{"location":"reference/audio_recording_logger/airtable/#audio_recording_logger.airtable.AirTable.__init__","title":"<code>__init__(url)</code>","text":"<p>Constructor for AirTable table.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>URL of AirTable table.</p> required Source code in <code>src/audio_recording_logger/airtable.py</code> <pre><code>def __init__(self, url: str) -&gt; None:\n\"\"\"Constructor for AirTable table.\n    Args:\n        url (str): URL of AirTable table.\n    \"\"\"\nself.url = url\nself.headers = {\n\"Authorization\": f\"Bearer {os.environ['AIRTABLE_API_KEY']}\",\n\"Content-Type\": \"application/json\",\n}\n</code></pre>"},{"location":"reference/audio_recording_logger/airtable/#audio_recording_logger.airtable.AirTable.add_records","title":"<code>add_records(records)</code>","text":"<p>Add records to AirTable table.</p> <p>Parameters:</p> Name Type Description Default <code>records</code> <code>List[Dict[str, Any]]</code> <p>List of records in AirTable format.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>Whether upload was a success.</p> Source code in <code>src/audio_recording_logger/airtable.py</code> <pre><code>def add_records(self, records: List[Dict[str, Any]]) -&gt; bool:\n\"\"\"Add records to AirTable table.\n    Args:\n        records (List[Dict[str, Any]]): List of records in AirTable format.\n    Returns:\n        bool: Whether upload was a success.\n    \"\"\"\ntry:\nresponse = requests.post(\nself.url, headers=self.headers, data=json.dumps({\"records\": records})\n)\nexcept Exception as exc:\nprint(exc)\nreturn False\nelse:\nif response.ok:\nreturn True\nelse:\nprint(f\"Failed to patch {records}\")\nreturn False\n</code></pre>"},{"location":"reference/audio_recording_logger/airtable/#audio_recording_logger.airtable.AirTable.batch_add_records","title":"<code>batch_add_records(records)</code>","text":"<p>Allow batching of record addition due to 10-element limit, then push.</p> <p>Parameters:</p> Name Type Description Default <code>records</code> <code>List[Dict[str, Any]]</code> <p>List of records in AirTable format.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>Whether upload was a success.</p> Source code in <code>src/audio_recording_logger/airtable.py</code> <pre><code>def batch_add_records(self, records: List[Dict[str, Any]]) -&gt; bool:\n\"\"\"Allow batching of record addition due to 10-element limit, then push.\n    Args:\n        records (List[Dict[str, Any]]): List of records in AirTable format.\n    Returns:\n        bool: Whether upload was a success.\n    \"\"\"\nbatch_size = 10\nfor idx in range(0, len(records), batch_size):\nbatch = records[idx : idx + batch_size]\nsuccess = self.add_records(batch)\nif not success:\nreturn success\nreturn True\n</code></pre>"},{"location":"reference/audio_recording_logger/lambda_function/","title":"AWS Lambda Event Handler","text":""},{"location":"reference/audio_recording_logger/lambda_function/#audio_recording_logger.lambda_function","title":"<code>audio_recording_logger.lambda_function</code>","text":""},{"location":"reference/audio_recording_logger/lambda_function/#audio_recording_logger.lambda_function.calculate_audio_duration","title":"<code>calculate_audio_duration(size_bytes, sample_rate, bit_depth=None, bit_rate=None, num_channels=1)</code>","text":"<p>Calculates audio duration based on audio file metadata.</p> <p>Parameters:</p> Name Type Description Default <code>size_bytes</code> <code>int</code> <p>Size of file in bytes.</p> required <code>sample_rate</code> <code>int</code> <p>Sample rate of audio.</p> required <code>bit_depth</code> <code>int</code> <p>Bit depth of audio, e.g. 16. Defaults to None.</p> <code>None</code> <code>bit_rate</code> <code>int</code> <p>Bit rate of audio if compressed, e.g. 95kbps. Defaults to None.</p> <code>None</code> <code>num_channels</code> <code>int</code> <p>Number of channels in audio. Defaults to 1 (mono).</p> <code>1</code> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Estimated audio duration, in seconds.</p> Source code in <code>src/audio_recording_logger/lambda_function.py</code> <pre><code>def calculate_audio_duration(\nsize_bytes: int,\nsample_rate: int,\nbit_depth: int = None,\nbit_rate: int = None,\nnum_channels: int = 1,\n) -&gt; int:\n\"\"\"Calculates audio duration based on audio file metadata.\n    Args:\n        size_bytes (int): Size of file in bytes.\n        sample_rate (int): Sample rate of audio.\n        bit_depth (int, optional): Bit depth of audio, e.g. 16. Defaults to None.\n        bit_rate (int, optional): Bit rate of audio if compressed, e.g. 95kbps. Defaults to None.\n        num_channels (int, optional): Number of channels in audio. Defaults to 1 (mono).\n    Returns:\n        int: Estimated audio duration, in seconds.\n    \"\"\"\nif not bit_rate:\nbit_rate = bit_depth * sample_rate\nbits = size_bytes * 8\nduration = bits / (bit_rate * num_channels)\nreturn ceil(duration)\n</code></pre>"},{"location":"reference/audio_recording_logger/lambda_function/#audio_recording_logger.lambda_function.get_log_files","title":"<code>get_log_files(bucket, manifest_file_path)</code>","text":"<p>Gets all log files as listed in S3 inventory manifest file.</p> <p>Parameters:</p> Name Type Description Default <code>bucket</code> <code>str</code> <p>AWS S3 manifest file's bucket name.</p> required <code>manifest_file_path</code> <code>str</code> <p>AWS S3 path to manifest file.</p> required <p>Returns:</p> Type Description <code>pd.DataFrame</code> <p>pd.DataFrame: DataFrame of all log files, concatenated.</p> Source code in <code>src/audio_recording_logger/lambda_function.py</code> <pre><code>def get_log_files(bucket: str, manifest_file_path: str) -&gt; pd.DataFrame:\n\"\"\"Gets all log files as listed in S3 inventory manifest file.\n    Args:\n        bucket (str): AWS S3 manifest file's bucket name.\n        manifest_file_path (str): AWS S3 path to manifest file.\n    Returns:\n        pd.DataFrame: DataFrame of all log files, concatenated.\n    \"\"\"\nmanifest_file = s3_client.get_object(bucket, manifest_file_path)\nfiles = json.loads(manifest_file)[\"files\"]\nfile_keys = [file[\"key\"] for file in files]\ndfs = []\nfor key in file_keys:\nlog_file = s3_client.get_object(bucket, key)\nlog_file_df = pd.read_csv(io.BytesIO(log_file), compression=\"gzip\", header=None)\ndfs.append(log_file_df)\nreturn pd.concat(dfs)\n</code></pre>"},{"location":"reference/audio_recording_logger/lambda_function/#audio_recording_logger.lambda_function.groupby_language_total_bytes","title":"<code>groupby_language_total_bytes(df, folder)</code>","text":"<p>Filters DataFrame by folder, then groups by:</p> <ul> <li><code>date</code>,</li> <li><code>folder</code>,</li> <li><code>language</code>,</li> <li><code>language-code</code>,</li> </ul> <p>then sums the duration of each group.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>pd.DataFrame</code> <p>Preprocessed DataFrame to group.</p> required <code>folder</code> <code>str</code> <p>Name of folder to filter for.</p> required <p>Returns:</p> Type Description <code>pd.DataFrame</code> <p>pd.DataFrame: Filtered and grouped-by DataFrame.</p> Source code in <code>src/audio_recording_logger/lambda_function.py</code> <pre><code>def groupby_language_total_bytes(df: pd.DataFrame, folder: str) -&gt; pd.DataFrame:\n\"\"\"Filters DataFrame by folder, then groups by:\n    - `date`,\n    - `folder`,\n    - `language`,\n    - `language-code`,\n    then sums the duration of each group.\n    Args:\n        df (pd.DataFrame): Preprocessed DataFrame to group.\n        folder (str): Name of folder to filter for.\n    Returns:\n        pd.DataFrame: Filtered and grouped-by DataFrame.\n    \"\"\"\nfiltered_df = df[df[\"folder\"] == folder]\nreturn pd.DataFrame(\nfiltered_df.groupby([\"date\", \"folder\", \"language\", \"language-code\"])[\n\"size\"\n].agg(\"sum\")\n).reset_index()\n</code></pre>"},{"location":"reference/audio_recording_logger/lambda_function/#audio_recording_logger.lambda_function.lambda_handler","title":"<code>lambda_handler(event, context)</code>","text":"<p>Event listener for S3 event and calls the daily logger function.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>AWS Event</code> <p>A JSON-formatted document that contains data for a Lambda function to process.</p> required <code>context</code> <code>AWS Context</code> <p>An object that provides methods and properties that provide information about the invocation, function, and runtime environment.</p> required Source code in <code>src/audio_recording_logger/lambda_function.py</code> <pre><code>def lambda_handler(event, context):\n\"\"\"Event listener for S3 event and calls the daily logger function.\n    Args:\n        event (AWS Event):\n            A JSON-formatted document that contains data for a Lambda function to process.\n        context (AWS Context):\n            An object that provides methods and properties that provide information about the invocation, function, and runtime environment.\n    \"\"\"\n# manifest.json file\nbucket = event[\"Records\"][0][\"s3\"][\"bucket\"][\"name\"]\nmanifest_file_path = unquote_plus(\nevent[\"Records\"][0][\"s3\"][\"object\"][\"key\"], encoding=\"utf-8\"\n)\nmanifest_file_date = manifest_file_path.split(\"/\")[-2].replace(\"T01-00Z\", \"\")\nquery_date = datetime.strptime(manifest_file_date, \"%Y-%m-%d\").date()\nmain(bucket, manifest_file_path, query_date)\n</code></pre>"},{"location":"reference/audio_recording_logger/lambda_function/#audio_recording_logger.lambda_function.main","title":"<code>main(bucket, manifest_file_path, query_date)</code>","text":"<p>Main function to be executed by <code>lambda_handler</code>.</p> <ul> <li>Gets all log files from manifest file, then preprocesses it.</li> <li>Gets all audio in <code>training</code> and <code>archive</code> folder.<ul> <li>Groups audios based on language code.</li> <li>Calculates total audio duration for each language code.</li> <li>Converts <code>date</code> column to string for AirTable upload purposes.</li> <li>Drops unused <code>size</code> column.</li> </ul> </li> <li>Push both resultant DataFrames to AirTable.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>bucket</code> <code>str</code> <p>AWS S3 manifest file's bucket name.</p> required <code>manifest_file_path</code> <code>str</code> <p>AWS S3 path to manifest file.</p> required <code>query_date</code> <code>datetime.date</code> <p>Query date to filter with.</p> required Source code in <code>src/audio_recording_logger/lambda_function.py</code> <pre><code>def main(bucket: str, manifest_file_path: str, query_date: datetime.date) -&gt; None:\n\"\"\"Main function to be executed by `lambda_handler`.\n    - Gets all log files from manifest file, then preprocesses it.\n    - Gets all audio in `training` and `archive` folder.\n        - Groups audios based on language code.\n        - Calculates total audio duration for each language code.\n        - Converts `date` column to string for AirTable upload purposes.\n        - Drops unused `size` column.\n    - Push both resultant DataFrames to AirTable.\n    Args:\n        bucket (str): AWS S3 manifest file's bucket name.\n        manifest_file_path (str): AWS S3 path to manifest file.\n        query_date (datetime.date): Query date to filter with.\n    \"\"\"\n# get all files, create dataframe, apply preprocessing\ndf = preprocess_dataframe(get_log_files(bucket, manifest_file_path))\n# filter by date\ndf = df[df[\"date\"] == query_date]\n# training dataframe\ntraining = groupby_language_total_bytes(df, \"training\")\ntraining[\"duration\"] = training[\"size\"].apply(\nlambda x: calculate_audio_duration(x, sample_rate=24000, bit_depth=16)\n)\ntraining[\"date\"] = training[\"date\"].apply(str)\ntraining = training.drop(labels=[\"size\"], axis=1)\n# archive dataframe\narchive = groupby_language_total_bytes(df, \"archive\")\narchive[\"duration\"] = archive[\"size\"].apply(\nlambda x: calculate_audio_duration(x, sample_rate=16000, bit_rate=95000)\n)\narchive[\"date\"] = archive[\"date\"].apply(str)\narchive = archive.drop(labels=[\"size\"], axis=1)\nairtable = AirTable(\"https://api.airtable.com/v0/app1j9JeeX1jXegnL/Master\")\nairtable.batch_add_records(\n[{\"fields\": d} for d in archive.to_dict(orient=\"records\")]\n)\nairtable.batch_add_records(\n[{\"fields\": d} for d in training.to_dict(orient=\"records\")]\n)\n</code></pre>"},{"location":"reference/audio_recording_logger/lambda_function/#audio_recording_logger.lambda_function.preprocess_dataframe","title":"<code>preprocess_dataframe(df)</code>","text":"<p>Perform basic preprocessing on concatenated S3 inventory log files.</p> <ul> <li>Rename columns to <code>bucket</code>, <code>key</code>, <code>size</code>, and <code>last_modified_date</code>.</li> <li>Converts <code>date</code> column to <code>datetime</code> type.</li> <li>Gets language code of item based on <code>key</code>, e.g. <code>en-AU</code>.</li> <li>Gets language of item based on <code>language</code>, e.g. <code>en</code>.</li> <li>Gets folder name of item based on <code>key</code>, e.g. <code>training</code>, <code>archive</code>.</li> <li>Gets filename suffix based on <code>key</code>, e.g. <code>aac</code>, <code>wav</code>.</li> <li>Only filters for audio files based on extensions found in <code>AUDIO_EXTENSIONS</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>pd.DataFrame</code> <p>DataFrame of all log files, concatenated.</p> required <p>Returns:</p> Type Description <code>pd.DataFrame</code> <p>pd.DataFrame: Preprocessed DataFrame based on the outline above.</p> Source code in <code>src/audio_recording_logger/lambda_function.py</code> <pre><code>def preprocess_dataframe(df: pd.DataFrame) -&gt; pd.DataFrame:\n\"\"\"Perform basic preprocessing on concatenated S3 inventory log files.\n    - Rename columns to `bucket`, `key`, `size`, and `last_modified_date`.\n    - Converts `date` column to `datetime` type.\n    - Gets language code of item based on `key`, e.g. `en-AU`.\n    - Gets language of item based on `language`, e.g. `en`.\n    - Gets folder name of item based on `key`, e.g. `training`, `archive`.\n    - Gets filename suffix based on `key`, e.g. `aac`, `wav`.\n    - Only filters for audio files based on extensions found in `AUDIO_EXTENSIONS`.\n    Args:\n        df (pd.DataFrame): DataFrame of all log files, concatenated.\n    Returns:\n        pd.DataFrame: Preprocessed DataFrame based on the outline above.\n    \"\"\"\ndf.columns = [\"bucket\", \"key\", \"size\", \"last_modified_date\"]\ndf[\"date\"] = pd.to_datetime(df[\"last_modified_date\"]).dt.date\ndf[\"language-code\"] = df[\"key\"].apply(lambda key: key.split(\"/\")[-2])\ndf[\"language\"] = df[\"language-code\"].apply(lambda x: x.split(\"-\")[0])\ndf[\"folder\"] = df[\"key\"].apply(lambda key: key.split(\"/\")[0])\ndf[\"suffix\"] = df[\"key\"].apply(lambda key: key.split(\"/\")[-1].split(\".\")[-1])\ndf = df[df[\"suffix\"].apply(lambda x: x in AUDIO_EXTENSIONS)]\nreturn df\n</code></pre>"},{"location":"reference/audio_recording_logger/s3_utils/","title":"AWS S3 Utilities","text":""},{"location":"reference/audio_recording_logger/s3_utils/#audio_recording_logger.s3_utils","title":"<code>audio_recording_logger.s3_utils</code>","text":""},{"location":"reference/audio_recording_logger/s3_utils/#audio_recording_logger.s3_utils.S3Client","title":"<code>S3Client</code>","text":"Source code in <code>src/audio_recording_logger/s3_utils.py</code> <pre><code>class S3Client:\ndef __init__(self, region_name=\"us-east-1\"):\n\"\"\"AWS S3 Client Constructor.\n        Args:\n            region_name (str, optional): AWS S3 region. Defaults to \"us-east-1\".\n        \"\"\"\nself.client = boto3.client(\"s3\", region_name=region_name)\nself.resource = boto3.resource(\"s3\", region_name=region_name)\ndef get_object(self, bucket: str, key: str) -&gt; Any:\n\"\"\"Gets object from S3.\n        Args:\n            bucket (str): S3 bucket name.\n            key (str): Key to file in bucket.\n        Returns:\n            Any: S3 Object retrieved.\n        \"\"\"\ntry:\ns3_object = self.client.get_object(Bucket=bucket, Key=key)[\"Body\"].read()\nexcept Exception:\nreturn None\nelse:\nreturn s3_object\n</code></pre>"},{"location":"reference/audio_recording_logger/s3_utils/#audio_recording_logger.s3_utils.S3Client.__init__","title":"<code>__init__(region_name='us-east-1')</code>","text":"<p>AWS S3 Client Constructor.</p> <p>Parameters:</p> Name Type Description Default <code>region_name</code> <code>str</code> <p>AWS S3 region. Defaults to \"us-east-1\".</p> <code>'us-east-1'</code> Source code in <code>src/audio_recording_logger/s3_utils.py</code> <pre><code>def __init__(self, region_name=\"us-east-1\"):\n\"\"\"AWS S3 Client Constructor.\n    Args:\n        region_name (str, optional): AWS S3 region. Defaults to \"us-east-1\".\n    \"\"\"\nself.client = boto3.client(\"s3\", region_name=region_name)\nself.resource = boto3.resource(\"s3\", region_name=region_name)\n</code></pre>"},{"location":"reference/audio_recording_logger/s3_utils/#audio_recording_logger.s3_utils.S3Client.get_object","title":"<code>get_object(bucket, key)</code>","text":"<p>Gets object from S3.</p> <p>Parameters:</p> Name Type Description Default <code>bucket</code> <code>str</code> <p>S3 bucket name.</p> required <code>key</code> <code>str</code> <p>Key to file in bucket.</p> required <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>S3 Object retrieved.</p> Source code in <code>src/audio_recording_logger/s3_utils.py</code> <pre><code>def get_object(self, bucket: str, key: str) -&gt; Any:\n\"\"\"Gets object from S3.\n    Args:\n        bucket (str): S3 bucket name.\n        key (str): Key to file in bucket.\n    Returns:\n        Any: S3 Object retrieved.\n    \"\"\"\ntry:\ns3_object = self.client.get_object(Bucket=bucket, Key=key)[\"Body\"].read()\nexcept Exception:\nreturn None\nelse:\nreturn s3_object\n</code></pre>"},{"location":"reference/audio_splitter/airtable_logger/","title":"AirTable Logger","text":""},{"location":"reference/audio_splitter/airtable_logger/#audio_splitter.airtable_logger","title":"<code>audio_splitter.airtable_logger</code>","text":""},{"location":"reference/audio_splitter/airtable_logger/#audio_splitter.airtable_logger.AirTableLogger","title":"<code>AirTableLogger</code>","text":"<p>A utility class to assist AirTable logging purposes. Contains attributes which holds the audio, ground truth, transcript, and language.</p> <p>Attributes:</p> Name Type Description <code>job_name</code> <code>str</code> <p>Job name/id.</p> <code>audio_url</code> <code>str</code> <p>URL to audio file.</p> <code>transcripts</code> <code>str</code> <p>Transcription received from AWS Transcribe.</p> <code>language</code> <code>str</code> <p>Language of audio.</p> <code>category(str)</code> <code>str</code> <p>Type of audio present, defaults to <code>CHILD</code> for first log.</p> Source code in <code>src/audio_splitter/airtable_logger.py</code> <pre><code>class AirTableLogger:\n\"\"\"\n    A utility class to assist AirTable logging purposes.\n    Contains attributes which holds the audio, ground truth, transcript, and language.\n    Attributes:\n        job_name (str): Job name/id.\n        audio_url (str): URL to audio file.\n        transcripts (str): Transcription received from AWS Transcribe.\n        language (str): Language of audio.\n        category(str): Type of audio present, defaults to `CHILD` for first log.\n    \"\"\"\ndef __init__(\nself,\njob_name: str,\naudio_url: str,\ntranscript: str,\nlanguage: str,\n):\n\"\"\"Constructor for the `AirTableLogger` class.\n        Args:\n            job_name (str): Job name/id.\n            audio_url (str): URL to audio file.\n            transcript (str): Transcription received from AWS Transcribe.\n            language (str): Language of audio.\n        \"\"\"\nself.job_name = job_name\nself.audio_url = audio_url\nself.transcript = transcript\nself.language = language\nself.category = \"CHILD\"\ndef log_to_airtable(self):\n\"\"\"Logs `self` attributes to AirTable.\"\"\"\nfields = {\n\"Job Name\": self.job_name,\n\"Audio\": [{\"url\": self.audio_url}],\n\"Language\": self.language,\n\"Transcript\": self.transcript,\n\"Category\": self.category,\n}\nairtable_url = \"https://api.airtable.com/v0/appMU2kEdFeVZJ0SS/Master\"\napi_key = os.environ[\"AIRTABLE_API_KEY\"]\nheaders = {\n\"Authorization\": f\"Bearer {api_key}\",\n\"Content-Type\": \"application/json\",\n}\npayload = json.dumps({\"records\": [{\"fields\": fields}]})\ntry:\nresponse = requests.post(airtable_url, headers=headers, data=payload)\nexcept Exception as exc:\nprint(exc)\nelse:\nif response.ok:\nprint(\"Successfully logged to AirTable\")\nelse:\nprint(\"Failed to log to AirTable\")\n</code></pre>"},{"location":"reference/audio_splitter/airtable_logger/#audio_splitter.airtable_logger.AirTableLogger.__init__","title":"<code>__init__(job_name, audio_url, transcript, language)</code>","text":"<p>Constructor for the <code>AirTableLogger</code> class.</p> <p>Parameters:</p> Name Type Description Default <code>job_name</code> <code>str</code> <p>Job name/id.</p> required <code>audio_url</code> <code>str</code> <p>URL to audio file.</p> required <code>transcript</code> <code>str</code> <p>Transcription received from AWS Transcribe.</p> required <code>language</code> <code>str</code> <p>Language of audio.</p> required Source code in <code>src/audio_splitter/airtable_logger.py</code> <pre><code>def __init__(\nself,\njob_name: str,\naudio_url: str,\ntranscript: str,\nlanguage: str,\n):\n\"\"\"Constructor for the `AirTableLogger` class.\n    Args:\n        job_name (str): Job name/id.\n        audio_url (str): URL to audio file.\n        transcript (str): Transcription received from AWS Transcribe.\n        language (str): Language of audio.\n    \"\"\"\nself.job_name = job_name\nself.audio_url = audio_url\nself.transcript = transcript\nself.language = language\nself.category = \"CHILD\"\n</code></pre>"},{"location":"reference/audio_splitter/airtable_logger/#audio_splitter.airtable_logger.AirTableLogger.log_to_airtable","title":"<code>log_to_airtable()</code>","text":"<p>Logs <code>self</code> attributes to AirTable.</p> Source code in <code>src/audio_splitter/airtable_logger.py</code> <pre><code>def log_to_airtable(self):\n\"\"\"Logs `self` attributes to AirTable.\"\"\"\nfields = {\n\"Job Name\": self.job_name,\n\"Audio\": [{\"url\": self.audio_url}],\n\"Language\": self.language,\n\"Transcript\": self.transcript,\n\"Category\": self.category,\n}\nairtable_url = \"https://api.airtable.com/v0/appMU2kEdFeVZJ0SS/Master\"\napi_key = os.environ[\"AIRTABLE_API_KEY\"]\nheaders = {\n\"Authorization\": f\"Bearer {api_key}\",\n\"Content-Type\": \"application/json\",\n}\npayload = json.dumps({\"records\": [{\"fields\": fields}]})\ntry:\nresponse = requests.post(airtable_url, headers=headers, data=payload)\nexcept Exception as exc:\nprint(exc)\nelse:\nif response.ok:\nprint(\"Successfully logged to AirTable\")\nelse:\nprint(\"Failed to log to AirTable\")\n</code></pre>"},{"location":"reference/audio_splitter/lambda_function/","title":"AWS Lambda Event Handler","text":""},{"location":"reference/audio_splitter/lambda_function/#audio_splitter.lambda_function","title":"<code>audio_splitter.lambda_function</code>","text":""},{"location":"reference/audio_splitter/lambda_function/#audio_splitter.lambda_function.lambda_handler","title":"<code>lambda_handler(event, context)</code>","text":"<p>Event listener for S3 event and calls the split audio function.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>AWS Event</code> <p>A JSON-formatted document that contains data for a Lambda                function to process.</p> required <code>context</code> <code>AWS Event</code> <p>An object that provides methods and properties that provide                  information about the invocation, function, and runtime                  environment.</p> required <p>Raises:</p> Type Description <code>e</code> <p>Audio cannot be obtained from S3.</p> Source code in <code>src/audio_splitter/lambda_function.py</code> <pre><code>def lambda_handler(event, context):\n\"\"\"Event listener for S3 event and calls the split audio function.\n    Args:\n        event (AWS Event): A JSON-formatted document that contains data for a Lambda\n                           function to process.\n        context (AWS Event): An object that provides methods and properties that provide\n                             information about the invocation, function, and runtime\n                             environment.\n    Raises:\n        e: Audio cannot be obtained from S3.\n    \"\"\"\nbucket = event[\"Records\"][0][\"s3\"][\"bucket\"][\"name\"]\nkey = unquote_plus(event[\"Records\"][0][\"s3\"][\"object\"][\"key\"], encoding=\"utf-8\")\njob_name = os.path.splitext(os.path.basename(key))[0]\nfolder_name = os.path.basename(os.path.dirname(key))\ntry:\nresponse = s3_client.get_object(Bucket=bucket, Key=key)\ntask = json.loads(response[\"Body\"].read().decode(\"utf-8\"))\n# \"predictions\" if immediately correct after Transcribe\n# else take human \"annotations\"\nannotation_key = \"annotations\" if \"annotations\" in task else \"predictions\"\nannotations = task[annotation_key]\n# get the corresponding audio file extension\n_, audio_extension = os.path.splitext(os.path.basename(task[\"data\"][\"audio\"]))\nexcept Exception as e:\nprint(e)\nraise e\nelse:\n# get audio file from S3\naudio_file = get_audio_file(bucket, key, audio_extension)\nif audio_file:\n# splits audio + transcription based on annotation, exports to S3\nsplit_export_audio(\nannotations,\nannotation_key,\naudio_file,\nbucket,\nf\"{folder_name}/{job_name}\",\n)\naudio_extension = audio_extension[1:]  # removes the dot\n# moves original audio and text to `archive`\nfor ext in [audio_extension, \"srt\", \"txt\"]:\nmove_file(\nbucket,\nf\"{job_name}.{ext}\",\nf\"dropbox/{folder_name}\",\nf\"archive/{folder_name}\",\n)\n</code></pre>"},{"location":"reference/audio_splitter/lambda_function/#audio_splitter.lambda_function.split_export_audio","title":"<code>split_export_audio(annotations, annotation_key, audio_file, bucket, key_prefix)</code>","text":"<p>Splits <code>audio_file</code> based on JSON-formatted <code>annotations</code>, saves exports to <code>key_prefix</code>.</p> <p>Parameters:</p> Name Type Description Default <code>annotations</code> <code>List[Dict[str, Any]]</code> <p>description</p> required <code>annotation_key</code> <code>str</code> <p>JSON-formatted annotations exported by Label Studio.</p> required <code>audio_file</code> <code>str</code> <p>Key of annotation dictionary containing timestamps and               transcriptions.</p> required <code>bucket</code> <code>str</code> <p>Pre-signed URL pointing to the audio file of the JSON annotation.</p> required <code>key_prefix</code> <code>str</code> <p>AWS S3 key prefix path to save file.</p> required Source code in <code>src/audio_splitter/lambda_function.py</code> <pre><code>def split_export_audio(\nannotations: List[Dict[str, Any]],\nannotation_key: str,\naudio_file: str,\nbucket: str,\nkey_prefix: str,\n) -&gt; None:\n\"\"\"Splits `audio_file` based on JSON-formatted `annotations`, saves exports to\n    `key_prefix`.\n    Args:\n        annotations (List[Dict[str, Any]]): _description_\n        annotation_key (str): JSON-formatted annotations exported by Label Studio.\n        audio_file (str): Key of annotation dictionary containing timestamps and\n                          transcriptions.\n        bucket (str): Pre-signed URL pointing to the audio file of the JSON annotation.\n        key_prefix (str): AWS S3 key prefix path to save file.\n    \"\"\"\nfolder_name = os.path.basename(os.path.dirname(audio_file))\nlanguage = folder_name.split(\"-\")[0]\nanno = None\nif annotation_key == \"annotations\":\n# only get annotations created by admin\nanno = [\nannotation\nfor annotation in annotations\nif ADMIN_EMAIL[language] in annotation[\"created_username\"]\n]\nelif annotation_key == \"predictions\":\n# otherwise, take correctly predicted transcriptions\nanno = [annotation for annotation in annotations]\nif anno:\ntry:\nresult = anno[0][\"result\"]\nexcept Exception as exc:\nprint(exc)\n# only get annotations with start and end times, ignore labels &amp; region-wise GTs\nsegments = [\nd\nfor d in result\nif \"start\" in d[\"value\"].keys()\nand \"labels\" not in d[\"value\"].keys()\nand d[\"from_name\"] != \"region-ground-truth\"\n]\nfor idx, segment in enumerate(segments):\nsave_path = f\"training/{key_prefix}-{idx}\"\nvalues = segment[\"value\"]\ntry:\n# trim export audio segment\nstdout, stderr = trim_audio(audio_file, values[\"start\"], values[\"end\"])\ns3_client.put_object(Body=stdout, Bucket=bucket, Key=f\"{save_path}.wav\")\n# export audio segment's transcription\ns3_client.put_object(\nBody=values[\"text\"][0], Bucket=bucket, Key=f\"{save_path}.txt\"\n)\n# # TODO: uncomment to enable classifier data collection\n# # export audio segment for categorization\n# s3_client.put_object(\n#     Body=stdout,\n#     Bucket=bucket,\n#     Key=f\"categorisation/raw/{key_prefix}-{idx}.wav\",\n# )\n# # log to AirTable\n# audio_url = create_presigned_url(bucket, f\"{save_path}.wav\")\n# logger = AirTableLogger(\n#     os.path.basename(save_path),\n#     audio_url,\n#     values[\"text\"][0],\n#     folder_name,\n# )\n# logger.log_to_airtable()\nexcept Exception as exc:\nprint(f\"Error: {exc}\")\nprint(f\"Successfully split and exported to {key_prefix}\")\nelse:\nprint(\"Admin annotation not found\")\n</code></pre>"},{"location":"reference/audio_splitter/lambda_function/#audio_splitter.lambda_function.trim_audio","title":"<code>trim_audio(input_path, start, end)</code>","text":"<p>Trims audio from <code>input_path</code> from <code>start</code> to <code>end</code> (in seconds), pipes output audio stdout and stderr.</p> <p>Source.</p> <p>Parameters:</p> Name Type Description Default <code>input_path</code> <code>str</code> <p>Input file URL (<code>ffmpeg -i</code> option).</p> required <code>start</code> <code>float</code> <p>Timestamp (in seconds) of the start of the section to keep.</p> required <code>end</code> <code>float</code> <p>Specify time of the first audio sample that will be dropped.</p> required <p>Returns:</p> Type Description <code>Tuple[bytes, bytes]</code> <p>Tuple[bytes, bytes]: Tuple-pair of stdout and stderr bytes.</p> Source code in <code>src/audio_splitter/lambda_function.py</code> <pre><code>def trim_audio(input_path: str, start: float, end: float) -&gt; Tuple[bytes, bytes]:\n\"\"\"Trims audio from `input_path` from `start` to `end` (in seconds), pipes output\n    audio stdout and stderr.\n    [Source](https://github.com/kkroening/ffmpeg-python/issues/184#issuecomment-504390452).\n    Args:\n        input_path (str): Input file URL (`ffmpeg -i` option).\n        start (float): Timestamp (in seconds) of the start of the section to keep.\n        end (float): Specify time of the first audio sample that will be dropped.\n    Returns:\n        Tuple[bytes, bytes]: Tuple-pair of stdout and stderr bytes.\n    \"\"\"\ninput_stream = ffmpeg.input(input_path)\naud = input_stream.audio.filter_(\"atrim\", start=start, end=end).filter_(\n\"asetpts\", \"PTS-STARTPTS\"\n)\n# # uncomment for aac\n# output = ffmpeg.output(aud, \"pipe:\", format=\"adts\")\n# kaldi training format: wav, 16bit, 24khz, mono\n# ffmpeg -i in.aac -acodec pcm_s16le -ac 1 -ar 24000 out.wav\noutput = ffmpeg.output(\naud,\n\"pipe:\",\nacodec=\"pcm_s16le\",\nformat=\"wav\",\nac=1,\nar=24000,\n)\nstdout, stderr = output.run_async(pipe_stdout=True, pipe_stderr=True).communicate()\nreturn (stdout, stderr)\n</code></pre>"},{"location":"reference/audio_splitter/s3_utils/","title":"AWS S3 Utilities","text":""},{"location":"reference/audio_splitter/s3_utils/#audio_splitter.s3_utils","title":"<code>audio_splitter.s3_utils</code>","text":""},{"location":"reference/audio_splitter/s3_utils/#audio_splitter.s3_utils.create_presigned_url","title":"<code>create_presigned_url(bucket_name, object_name, expiration=3600)</code>","text":"<p>Generate a presigned URL to share an S3 object.</p> <p>Parameters:</p> Name Type Description Default <code>bucket_name</code> <code>str</code> <p>Bucket name</p> required <code>object_name</code> <code>str</code> <p>Name of object/file</p> required <code>expiration</code> <code>int</code> <p>Time in seconds for the presigned URL to remain                         valid. Defaults to 3600.</p> <code>3600</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Presigned URL as string. If error, returns <code>None</code>.</p> Source code in <code>src/audio_splitter/s3_utils.py</code> <pre><code>def create_presigned_url(\nbucket_name: str, object_name: str, expiration: int = 3600\n) -&gt; str:\n\"\"\"Generate a presigned URL to share an S3 object.\n    Args:\n        bucket_name (str): Bucket name\n        object_name (str): Name of object/file\n        expiration (int, optional): Time in seconds for the presigned URL to remain\n                                    valid. Defaults to 3600.\n    Returns:\n        str: Presigned URL as string. If error, returns `None`.\n    \"\"\"\ntry:\nresponse = s3_client.generate_presigned_url(\n\"get_object\",\nParams={\"Bucket\": bucket_name, \"Key\": object_name},\nExpiresIn=expiration,\n)\nexcept ClientError as exc:\nprint(exc)\nreturn None\nreturn response\n</code></pre>"},{"location":"reference/audio_splitter/s3_utils/#audio_splitter.s3_utils.get_audio_file","title":"<code>get_audio_file(bucket, key, audio_extension)</code>","text":"<p>Get corresponding audio file of JSON annotation (<code>key</code>) from AWS S3, in <code>bucket</code>.</p> <p>Parameters:</p> Name Type Description Default <code>bucket</code> <code>str</code> <p>Audio and JSON bucket name in S3.</p> required <code>key</code> <code>str</code> <p>JSON file key name in S3.</p> required <code>audio_extension</code> <code>str</code> <p>Audio extension.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Pre-signed URL pointing to the audio file of the JSON annotation.</p> Source code in <code>src/audio_splitter/s3_utils.py</code> <pre><code>def get_audio_file(bucket: str, key: str, audio_extension: str) -&gt; str:\n\"\"\"Get corresponding audio file of JSON annotation (`key`) from AWS S3, in `bucket`.\n    Args:\n        bucket (str): Audio and JSON bucket name in S3.\n        key (str): JSON file key name in S3.\n        audio_extension (str): Audio extension.\n    Returns:\n        str: Pre-signed URL pointing to the audio file of the JSON annotation.\n    \"\"\"\njob_name = os.path.splitext(os.path.basename(key))[0]\nfolder_name = os.path.basename(os.path.dirname(key))\naudio_file = f\"dropbox/{folder_name}/{job_name}{audio_extension}\"\ntry:\ns3_source_signed_url = s3_client.generate_presigned_url(\n\"get_object\",\nParams={\"Bucket\": bucket, \"Key\": audio_file},\nExpiresIn=SIGNED_URL_TIMEOUT,\n)\nexcept Exception as exc:\nprint(f\"Error: {exc}\")\nprint(f\"Failed to fetch key: {audio_file}\")\nreturn None\nelse:\nprint(f\"Successfully fetched {audio_file}\")\nreturn s3_source_signed_url\n</code></pre>"},{"location":"reference/audio_splitter/s3_utils/#audio_splitter.s3_utils.move_file","title":"<code>move_file(bucket, file, source, destination)</code>","text":"<p>Move <code>file</code> in <code>bucket</code> from <code>source</code> to <code>destination</code> folder.</p> <p>Parameters:</p> Name Type Description Default <code>bucket</code> <code>str</code> <p>S3 bucket name.</p> required <code>file</code> <code>str</code> <p>Name of file to be moved (without full-path).</p> required <code>source</code> <code>str</code> <p>Source folder in S3 bucket.</p> required <code>destination</code> <code>str</code> <p>Destination folder in S3 bucket.</p> required Source code in <code>src/audio_splitter/s3_utils.py</code> <pre><code>def move_file(bucket: str, file: str, source: str, destination: str) -&gt; None:\n\"\"\"Move `file` in `bucket` from `source` to `destination` folder.\n    Args:\n        bucket (str): S3 bucket name.\n        file (str): Name of file to be moved (without full-path).\n        source (str): Source folder in S3 bucket.\n        destination (str): Destination folder in S3 bucket.\n    \"\"\"\ns3_resource = boto3.resource(\"s3\")\ntry:\ns3_resource.Object(bucket, f\"{destination}/{file}\").copy_from(\nCopySource=f\"{bucket}/{source}/{file}\"\n)\ns3_resource.Object(bucket, f\"{source}/{file}\").delete()\nprint(\nf\"Moved file from {bucket}/{source}/{file} to {bucket}/{destination}/{file}\"\n)\nexcept Exception:\nprint(f\"{bucket}/{source}/{file} not available\")\n</code></pre>"},{"location":"reference/transcribe/aligner/","title":"Aligner","text":""},{"location":"reference/transcribe/aligner/#transcribe.aligner","title":"<code>transcribe.aligner</code>","text":""},{"location":"reference/transcribe/aligner/#transcribe.aligner.init_label_studio_annotation","title":"<code>init_label_studio_annotation()</code>","text":"<p>Initializes a pair of dictionaries in Label Studio annotation format.</p> <p>Returns:</p> Type Description <code>List[Dict[str, Any]]</code> <p>List[Dict[str, Any]]: List containing pair of dictionaries in Label Studio JSON</p> <code>List[Dict[str, Any]]</code> <p>annotation format.</p> Source code in <code>src/transcribe/aligner.py</code> <pre><code>def init_label_studio_annotation() -&gt; List[Dict[str, Any]]:\n\"\"\"Initializes a pair of dictionaries in Label Studio annotation format.\n    Returns:\n        List[Dict[str, Any]]: List containing pair of dictionaries in Label Studio JSON\n        annotation format.\n    \"\"\"\nreturn [\n{\n\"value\": {\"start\": -1, \"end\": -1, \"text\": []},\n\"id\": \"\",\n\"from_name\": \"transcription\",\n\"to_name\": \"audio\",\n\"type\": \"textarea\",\n},\n{\n\"value\": {\"start\": -1, \"end\": -1, \"labels\": [\"Sentence\"]},\n\"id\": \"\",\n\"from_name\": \"labels\",\n\"to_name\": \"audio\",\n\"type\": \"labels\",\n},\n{\n\"value\": {\"start\": -1, \"end\": -1, \"text\": []},\n\"id\": \"\",\n\"from_name\": \"region-ground-truth\",\n\"to_name\": \"audio\",\n\"type\": \"textarea\",\n},\n]\n</code></pre>"},{"location":"reference/transcribe/aligner/#transcribe.aligner.overlapping_segments","title":"<code>overlapping_segments(results, ground_truth, language, max_repeats=None)</code>","text":"<p>Segments Amazon Transcribe raw output to individual sentences based on overlapping regions.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>Dict[str, List]</code> <p>Resultant output received from AWS Transcribe.</p> required <code>ground_truth</code> <code>str</code> <p>Ground truth text for the corresponding annotation.</p> required <code>language</code> <code>str</code> <p>Language of the transcript-ground truth pair.</p> required <code>max_repeats</code> <code>int</code> <p>Maximum number of repeats when detecting for                          overlaps. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[Dict[str, Any]]</code> <p>List[Dict[str, Any]]: List of dictionaries with segment-wise annotations for</p> <code>List[Dict[str, Any]]</code> <p>Label Studio.</p> Source code in <code>src/transcribe/aligner.py</code> <pre><code>def overlapping_segments(\nresults: Dict[str, List], ground_truth: str, language: str, max_repeats: int = None\n) -&gt; List[Dict[str, Any]]:\n\"\"\"Segments Amazon Transcribe raw output to individual sentences based on\n    overlapping regions.\n    Args:\n        results (Dict[str, List]): Resultant output received from AWS Transcribe.\n        ground_truth (str): Ground truth text for the corresponding annotation.\n        language (str): Language of the transcript-ground truth pair.\n        max_repeats (int, optional): Maximum number of repeats when detecting for\n                                     overlaps. Defaults to None.\n    Returns:\n        List[Dict[str, Any]]: List of dictionaries with segment-wise annotations for\n        Label Studio.\n    \"\"\"\noutput = []\nsentence_counter = 0\ntranscripts = [\nitem[\"alternatives\"][0][\"content\"].lower().strip() for item in results[\"items\"]\n]\nground_truth = ground_truth.lower().strip().replace(\"-\", \" \").split(\" \")\n# gets approximate number of repeats for case where\n# len(ground_truth) &lt;&lt; len(transcripts)\n# multiplier also manually tweakable if needed, e.g. 3\nmultiplier = (\nmax_repeats if max_repeats else ceil(len(transcripts) / len(ground_truth))\n)\nground_truth *= multiplier\n# find overlaps and mark as new sequence\nhomophones = HOMOPHONES[language] if language in HOMOPHONES else None\naligned_transcripts, *_ = match_sequence(transcripts, ground_truth, homophones)\nfor _, g in groupby(enumerate(aligned_transcripts), lambda x: x[0] - x[1]):\n# add a newly initialized pair of lists if new sequence is detected\nseq = list(map(itemgetter(1), g))\n# first and last element of the sequence\nfirst, last = seq[0], seq[-1]\n# in case it overlaps only on punctuations, then skip\nif \"start_time\" not in results[\"items\"][first]:\ncontinue\noutput = output + init_label_studio_annotation()\nidx = sentence_counter * 3\ntext_dict = output[idx]\nlabel_dict = output[idx + 1]\nground_truth_dict = output[idx + 2]\nsentence_id = f\"sentence_{sentence_counter}\"\ntext_dict[\"id\"] = sentence_id\nlabel_dict[\"id\"] = sentence_id\nground_truth_dict[\"id\"] = sentence_id\ntext_values = text_dict[\"value\"]\nlabel_values = label_dict[\"value\"]\nground_truth_values = ground_truth_dict[\"value\"]\n# start time is at the first word of the sequence\n# end time is at the last word of the sequence\nfor d in [text_values, label_values, ground_truth_values]:\nd[\"start\"] = float(results[\"items\"][first][\"start_time\"])\nd[\"end\"] = float(results[\"items\"][last][\"end_time\"])\n# concat words in a sequence with whitespace\noverlap = [\" \".join(transcripts[first : last + 1])]\n# provide region-wise transcription and ground truth for convenience\nfor d in [text_values, ground_truth_values]:\nd[\"text\"] = overlap\nsentence_counter += 1\nreturn output\n</code></pre>"},{"location":"reference/transcribe/classifier/","title":"Classifier","text":""},{"location":"reference/transcribe/classifier/#transcribe.classifier","title":"<code>transcribe.classifier</code>","text":""},{"location":"reference/transcribe/classifier/#transcribe.classifier.SpeakerClassifier","title":"<code>SpeakerClassifier</code>","text":"<p>A class to run audio classification.</p> <p>Attributes:</p> Name Type Description <code>audio_url</code> <code>str</code> <p>S3 URL pointing to the audio.</p> Source code in <code>src/transcribe/classifier.py</code> <pre><code>class SpeakerClassifier:\n\"\"\"\n    A class to run audio classification.\n    Attributes:\n        audio_url (str): S3 URL pointing to the audio.\n    \"\"\"\ndef __init__(self, audio_url: str):\n\"\"\"Constructor for the `SpeakerClassifier` class.\n        Args:\n            audio_url (str): S3 URL pointing to the audio.\n        \"\"\"\nself.audio_url = audio_url\napi = \"audio-classifier-adult-child\"\nself.url = f\"https://ety3wzgylf.execute-api.ap-southeast-1.amazonaws.com/{api}\"\nself.headers = {\n\"Authorization\": os.environ[\"API_KEY\"],\n\"Content-Type\": \"application/json\",\n}\nself.payload = {\"audio_url\": self.audio_url}\ndef predict(self) -&gt; str:\n\"\"\"Predicts the audio's speaker type, either child or adult.\n        Returns:\n            str: \"ADULT\" or \"CHILD\", optionally \"None\" if errs.\n        \"\"\"\ntry:\nresponse = requests.post(\nself.url, headers=self.headers, data=json.dumps(self.payload)\n)\nexcept Exception as exc:\nprint(f\"Failed to predict for audio {self.audio_url}\")\nprint(exc)\nreturn \"None\"\nelse:\nif response.ok:\nreturn response.json()[\"body\"][\"prediction\"]\nelse:\nreturn \"None\"\n</code></pre>"},{"location":"reference/transcribe/classifier/#transcribe.classifier.SpeakerClassifier.__init__","title":"<code>__init__(audio_url)</code>","text":"<p>Constructor for the <code>SpeakerClassifier</code> class.</p> <p>Parameters:</p> Name Type Description Default <code>audio_url</code> <code>str</code> <p>S3 URL pointing to the audio.</p> required Source code in <code>src/transcribe/classifier.py</code> <pre><code>def __init__(self, audio_url: str):\n\"\"\"Constructor for the `SpeakerClassifier` class.\n    Args:\n        audio_url (str): S3 URL pointing to the audio.\n    \"\"\"\nself.audio_url = audio_url\napi = \"audio-classifier-adult-child\"\nself.url = f\"https://ety3wzgylf.execute-api.ap-southeast-1.amazonaws.com/{api}\"\nself.headers = {\n\"Authorization\": os.environ[\"API_KEY\"],\n\"Content-Type\": \"application/json\",\n}\nself.payload = {\"audio_url\": self.audio_url}\n</code></pre>"},{"location":"reference/transcribe/classifier/#transcribe.classifier.SpeakerClassifier.predict","title":"<code>predict()</code>","text":"<p>Predicts the audio's speaker type, either child or adult.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>\"ADULT\" or \"CHILD\", optionally \"None\" if errs.</p> Source code in <code>src/transcribe/classifier.py</code> <pre><code>def predict(self) -&gt; str:\n\"\"\"Predicts the audio's speaker type, either child or adult.\n    Returns:\n        str: \"ADULT\" or \"CHILD\", optionally \"None\" if errs.\n    \"\"\"\ntry:\nresponse = requests.post(\nself.url, headers=self.headers, data=json.dumps(self.payload)\n)\nexcept Exception as exc:\nprint(f\"Failed to predict for audio {self.audio_url}\")\nprint(exc)\nreturn \"None\"\nelse:\nif response.ok:\nreturn response.json()[\"body\"][\"prediction\"]\nelse:\nreturn \"None\"\n</code></pre>"},{"location":"reference/transcribe/homophones/","title":"Homophones","text":""},{"location":"reference/transcribe/homophones/#transcribe.homophones","title":"<code>transcribe.homophones</code>","text":""},{"location":"reference/transcribe/homophones/#transcribe.homophones.create_convert","title":"<code>create_convert(*families)</code>","text":"<p>Return a converter function that converts a list to the same list with only main words</p> <p>Parameters:</p> Name Type Description Default <code>families</code> <code>List[Set[str]]</code> <p>List of homophone families.</p> <code>()</code> <p>Returns:</p> Type Description <code>List[List[str]]</code> <p>List[List[str]]: True if all paths exist in <code>files</code></p> Source code in <code>src/transcribe/homophones.py</code> <pre><code>def create_convert(*families: List[Set[str]]) -&gt; List[List[str]]:\n\"\"\"Return a converter function that converts a list to the same list with\n    only main words\n    Arguments:\n        families (List[Set[str]]): List of homophone families.\n    Returns:\n        List[List[str]]: True if all paths exist in `files`\n    \"\"\"\nd = {w: main for main, *alternatives in map(list, families) for w in alternatives}\nreturn lambda L: [d.get(w, w) for w in L]\n</code></pre>"},{"location":"reference/transcribe/homophones/#transcribe.homophones.match_sequence","title":"<code>match_sequence(list1, list2, homophones)</code>","text":"<p>Finds index of overlaps between two lists given a homophone mapping.</p> <p>Parameters:</p> Name Type Description Default <code>list1</code> <code>List[str]</code> <p>List of words in a sequence.</p> required <code>list2</code> <code>List[str]</code> <p>List of words in another sequence for matching/comparison.</p> required <code>homophones</code> <code>List[Set[str]]</code> <p>List of homophone families.</p> required <p>Returns:</p> Type Description <code>Tuple[List[int], List[int], List[Tuple[str, int, int, int, int]]]</code> <p>Tuple[List[int], List[int], List[Tuple[str, int, int, int, int]]]: Pair of lists containing list of indices of overlap.</p> Source code in <code>src/transcribe/homophones.py</code> <pre><code>def match_sequence(\nlist1: List[str], list2: List[str], homophones: List[Set[str]]\n) -&gt; Tuple[List[int], List[int], List[Tuple[str, int, int, int, int]]]:\n\"\"\"Finds index of overlaps between two lists given a homophone mapping.\n    Args:\n        list1 (List[str]): List of words in a sequence.\n        list2 (List[str]): List of words in another sequence for matching/comparison.\n        homophones (List[Set[str]]): List of homophone families.\n    Returns:\n        Tuple[List[int], List[int], List[Tuple[str, int, int, int, int]]]:\n            Pair of lists containing list of indices of overlap.\n    \"\"\"\nconvert = create_convert(*homophones)\noutput1, output2 = [], []\ns = SequenceMatcher(None, convert(list1), convert(list2))\nopcodes = s.get_opcodes()\nfor block in s.get_matching_blocks():\nfor i in range(block.size):\noutput1.append(block.a + i)\noutput2.append(block.b + i)\nassert len(output1) == len(output2)\nreturn output1, output2, opcodes\n</code></pre>"},{"location":"reference/transcribe/lambda_function/","title":"AWS Lambda Event Handler","text":""},{"location":"reference/transcribe/lambda_function/#transcribe.lambda_function","title":"<code>transcribe.lambda_function</code>","text":""},{"location":"reference/transcribe/lambda_function/#transcribe.lambda_function.classify_mispronunciation","title":"<code>classify_mispronunciation(results, ground_truth, language)</code>","text":"<p>Classifies if a transcription result and ground truth text is a case of mispronunciation.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>Dict[str, List]</code> <p>Resultant output received from AWS Transcribe.</p> required <code>ground_truth</code> <code>str</code> <p>Ground truth text for the corresponding annotation.</p> required <code>language</code> <code>str</code> <p>Language of the transcript-ground truth pair.</p> required <p>Returns:</p> Name Type Description <code>Mispronunciation</code> <code>Mispronunciation</code> <p>Object of mispronunciation present.</p> Source code in <code>src/transcribe/lambda_function.py</code> <pre><code>def classify_mispronunciation(\nresults: Dict[str, List], ground_truth: str, language: str\n) -&gt; Mispronunciation:\n\"\"\"Classifies if a transcription result and ground truth text is a case of\n    mispronunciation.\n    Args:\n        results (Dict[str, List]): Resultant output received from AWS Transcribe.\n        ground_truth (str): Ground truth text for the corresponding annotation.\n        language (str): Language of the transcript-ground truth pair.\n    Returns:\n        Mispronunciation: Object of mispronunciation present.\n    \"\"\"\ndef _preprocess_sequence(sequence):\nreturn (\nsequence.replace(\"-\", \" \")\n.translate(str.maketrans(\"\", \"\", string.punctuation))\n.lower()\n.strip()\n)\ntranscripts = [\n_preprocess_sequence(item[\"alternatives\"][0][\"content\"])\nfor item in results[\"items\"]\n]\nground_truth = _preprocess_sequence(ground_truth).split()\nhomophones = HOMOPHONES[language] if language in HOMOPHONES else None\nmispronunciation = detect_mispronunciation(ground_truth, transcripts, homophones)\nreturn mispronunciation\n</code></pre>"},{"location":"reference/transcribe/lambda_function/#transcribe.lambda_function.get_ground_truth","title":"<code>get_ground_truth(ground_truth_filename_prefix)</code>","text":"<p>Attempts to grab ground truth file from S3, either ending in txt or srt.</p> <p>Parameters:</p> Name Type Description Default <code>ground_truth_filename_prefix</code> <code>str</code> <p>Prefix of ground truth file name.</p> required <p>Returns:</p> Type Description <code>Tuple[str, str]</code> <p>Tuple[str, str]: Pair of [ground truth string, ground truth file extension], otherwise <code>[None, None]</code>.</p> Source code in <code>src/transcribe/lambda_function.py</code> <pre><code>def get_ground_truth(ground_truth_filename_prefix: str) -&gt; Tuple[str, str]:\n\"\"\"Attempts to grab ground truth file from S3, either ending in txt or srt.\n    Args:\n        ground_truth_filename_prefix (str): Prefix of ground truth file name.\n    Returns:\n        Tuple[str, str]: Pair of [ground truth string, ground truth file extension],\n            otherwise `[None, None]`.\n    \"\"\"\ntxt_transcript_file = s3_client.get_object(\nBUCKET, f\"{ground_truth_filename_prefix}.txt\"\n)\nsrt_transcript_file = s3_client.get_object(\nBUCKET, f\"{ground_truth_filename_prefix}.srt\"\n)\n# if txt exists\nif txt_transcript_file:\nreturn (txt_transcript_file[\"Body\"].read().decode(\"utf-8\"), \"txt\")\nelif srt_transcript_file:\nreturn (srt2txt(srt_transcript_file[\"Body\"].read().decode(\"utf-8\")), \"srt\")\nelse:\nreturn (None, None)\n</code></pre>"},{"location":"reference/transcribe/lambda_function/#transcribe.lambda_function.get_language_code","title":"<code>get_language_code(filename)</code>","text":"<p>Get language code from filename for transcribing</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Audio filename with complete S3 path.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Language code of the audio file, formatted for AWS Transcribe.</p> Source code in <code>src/transcribe/lambda_function.py</code> <pre><code>def get_language_code(filename: str) -&gt; str:\n\"\"\"Get language code from filename for transcribing\n    Args:\n        filename (str): Audio filename with complete S3 path.\n    Returns:\n        str: Language code of the audio file, formatted for AWS Transcribe.\n    \"\"\"\nfolder = os.path.basename(os.path.dirname(filename))\nlanguage, country = folder.split(\"-\")\nlanguage_code = f\"{language}-{country.upper()}\"\nif language_code not in LANGUAGE_CODES:\n# defaults to US English and ID Indonesian if not supported\nreturn \"en-US\" if language == \"en\" else \"id-ID\"\nreturn language_code\n</code></pre>"},{"location":"reference/transcribe/lambda_function/#transcribe.lambda_function.lambda_handler","title":"<code>lambda_handler(event, context)</code>","text":"<p>Event listener for S3 event and calls Transcribe job.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>AWS Event</code> <p>A JSON-formatted document that contains data for a Lambda function to process.</p> required <code>context</code> <code>AWS Context</code> <p>An object that provides methods and properties that provide information about the invocation, function, and runtime environment.</p> required Source code in <code>src/transcribe/lambda_function.py</code> <pre><code>def lambda_handler(event, context):\n\"\"\"Event listener for S3 event and calls Transcribe job.\n    Args:\n        event (AWS Event):\n            A JSON-formatted document that contains data for a Lambda function\n            to process.\n        context (AWS Context):\n            An object that provides methods and properties that provide information\n            about the invocation, function, and runtime environment.\n    \"\"\"\nbucket = event[\"Records\"][0][\"s3\"][\"bucket\"][\"name\"]\nkey = unquote_plus(event[\"Records\"][0][\"s3\"][\"object\"][\"key\"], encoding=\"utf-8\")\nmain(f\"s3://{bucket}/{key}\")\n</code></pre>"},{"location":"reference/transcribe/lambda_function/#transcribe.lambda_function.main","title":"<code>main(audio_file)</code>","text":"<p>Main function to run Transcribe, generate Label Studio JSON-annotation, and saves JSON to S3.</p> <p>Parameters:</p> Name Type Description Default <code>audio_file</code> <code>str</code> <p>Audio filename with complete S3 path.</p> required Source code in <code>src/transcribe/lambda_function.py</code> <pre><code>def main(audio_file: str):\n\"\"\"Main function to run Transcribe, generate Label Studio JSON-annotation,\n    and saves JSON to S3.\n    Args:\n        audio_file (str): Audio filename with complete S3 path.\n    \"\"\"\nEXT2FORMAT = {\"wav\": \"wav\", \"m4a\": \"mp4\", \"aac\": \"mp4\"}\njob_name, audio_extension = os.path.splitext(os.path.basename(audio_file))\naudio_extension = audio_extension[1:]\nfolder_name = os.path.basename(os.path.dirname(audio_file))\nlanguage = folder_name.split(\"-\")[0]\nlanguage_code = get_language_code(audio_file)\nground_truth, ground_truth_ext = get_ground_truth(\nf\"dropbox/{folder_name}/{job_name}\"\n)\nspeaker_type = SpeakerClassifier(audio_file).predict()\nif speaker_type == \"ADULT\":\nprint(\"Adult audio detected. Archiving audio.\")\nfor ext in [audio_extension, ground_truth_ext]:\ns3_client.move_file(\nBUCKET,\nf\"{job_name}.{ext}\",\nf\"dropbox/{folder_name}\",\nf\"archive/adult/{folder_name}\",\n)\nreturn\nstatus, results, task = transcribe_client.transcribe_file(\njob_name,\naudio_file,\nmedia_format=EXT2FORMAT[audio_extension],\nlanguage_code=language_code,\n)\ntranscribed_text = task[\"predictions\"][0][\"result\"][0][\"value\"][\"text\"][0]\nmispronunciation = None\nif status == TranscribeStatus.SUCCESS:\nif ground_truth is not None:\n# classify for mispronunciation\nmispronunciation = classify_mispronunciation(\nresults, ground_truth, language\n)\n# add ground truth to Label Studio JSON-annotated task (for reference)\ntask[\"data\"][\"text\"] = ground_truth\n# add region-wise transcriptions and ground truth (for convenience\n# of labeler)\ntask[\"predictions\"][0][\"result\"] += overlapping_segments(\nresults, ground_truth, language, max_repeats=3\n)\nif status == TranscribeStatus.FAILED or transcribed_text == \"\":\n# archive Transcribe-failed annotations\nsave_path = f\"archive/{folder_name}/{job_name}.json\"\n# move audios to `archive`\nfor ext in [audio_extension, ground_truth_ext]:\ns3_client.move_file(\nBUCKET,\nf\"{job_name}.{ext}\",\nf\"dropbox/{folder_name}\",\nf\"archive/{folder_name}\",\n)\nelse:\n# otherwise, save annotations to `label-studio/verified` for audio splitting\nsave_path = f\"label-studio/verified/{folder_name}/{job_name}.json\"\nif mispronunciation:\n# copy audio to a separate folder for annotation\ns3_client.copy_file(\nBUCKET,\nf\"{job_name}.{audio_extension}\",\nf\"dropbox/{folder_name}\",\nf\"mispronunciations/raw/{folder_name}\",\n)\n# log results to AirTable\nmispronunciation.job_name = job_name\nmispronunciation.language = folder_name\nmispronunciation.audio_url = s3_client.create_presigned_url(\nBUCKET,\nf\"mispronunciations/raw/{folder_name}/{job_name}.{audio_extension}\",\nSIGNED_URL_TIMEOUT,\n)\n# export JSON to respective folders in S3\ns3_client.put_object(task, BUCKET, save_path)\nprint(f\"File {save_path} successfully created and saved.\")\n</code></pre>"},{"location":"reference/transcribe/mispronunciation/","title":"Mispronunciation","text":""},{"location":"reference/transcribe/mispronunciation/#transcribe.mispronunciation","title":"<code>transcribe.mispronunciation</code>","text":""},{"location":"reference/transcribe/mispronunciation/#transcribe.mispronunciation.Mispronunciation","title":"<code>Mispronunciation</code>","text":"<p>A class to represent a Mispronunciation. Contains attributes which holds the type and differences.</p> <p>Parameters:</p> Name Type Description Default <code>job_name</code> <code>str</code> <p>Job name/id.</p> required <code>audio_url</code> <code>str</code> <p>URL to audio file.</p> required <code>language</code> <code>str</code> <p>Language of audio.</p> required <code>type</code> <code>MispronunciationType</code> <p>Type of mispronunciation/disfluency present.</p> required <code>lists</code> <code>Tuple[List[str], List[str]]</code> <p>Input list of strings taken for comparison.</p> required <code>differences</code> <code>Tuple[List[str], List[str]]</code> <p>Differences of list of strings that                                        resulted in the type verdict.</p> required Source code in <code>src/transcribe/mispronunciation.py</code> <pre><code>class Mispronunciation:\n\"\"\"\n    A class to represent a Mispronunciation.\n    Contains attributes which holds the type and differences.\n    Arguments:\n        job_name (str): Job name/id.\n        audio_url (str): URL to audio file.\n        language (str): Language of audio.\n        type (MispronunciationType): Type of mispronunciation/disfluency present.\n        lists (Tuple[List[str], List[str]]): Input list of strings taken for comparison.\n        differences (Tuple[List[str], List[str]]): Differences of list of strings that\n                                                   resulted in the type verdict.\n    \"\"\"\ndef __init__(\nself,\ntype: MispronunciationType,\nlists: Tuple[List[str], List[str]],\ndifferences: Tuple[List[str], List[str]],\nopcodes: List[Tuple[str, int, int, int, int]],\n):\n\"\"\"Constructor for the `Mispronunciation` class.\n        Args:\n            type (MispronunciationType): Type of mispronunciation/disfluency present.\n            lists (Tuple[List[str], List[str]]): Input list of strings taken for\n                                                 comparison.\n            differences (Tuple[List[str], List[str]]): Differences of list of strings\n                                                    that resulted in the type verdict.\n            opcodes (List[Tuple[str, int, int, int, int]]): Opcodes from `diff` library.\n        \"\"\"\nself.job_name = None\nself.audio_url = None\nself.language = None\nself.type = type\nself.lists = lists\nself.differences = differences\nself.opcodes = opcodes\n</code></pre>"},{"location":"reference/transcribe/mispronunciation/#transcribe.mispronunciation.Mispronunciation.__init__","title":"<code>__init__(type, lists, differences, opcodes)</code>","text":"<p>Constructor for the <code>Mispronunciation</code> class.</p> <p>Parameters:</p> Name Type Description Default <code>type</code> <code>MispronunciationType</code> <p>Type of mispronunciation/disfluency present.</p> required <code>lists</code> <code>Tuple[List[str], List[str]]</code> <p>Input list of strings taken for                                  comparison.</p> required <code>differences</code> <code>Tuple[List[str], List[str]]</code> <p>Differences of list of strings                                     that resulted in the type verdict.</p> required <code>opcodes</code> <code>List[Tuple[str, int, int, int, int]]</code> <p>Opcodes from <code>diff</code> library.</p> required Source code in <code>src/transcribe/mispronunciation.py</code> <pre><code>def __init__(\nself,\ntype: MispronunciationType,\nlists: Tuple[List[str], List[str]],\ndifferences: Tuple[List[str], List[str]],\nopcodes: List[Tuple[str, int, int, int, int]],\n):\n\"\"\"Constructor for the `Mispronunciation` class.\n    Args:\n        type (MispronunciationType): Type of mispronunciation/disfluency present.\n        lists (Tuple[List[str], List[str]]): Input list of strings taken for\n                                             comparison.\n        differences (Tuple[List[str], List[str]]): Differences of list of strings\n                                                that resulted in the type verdict.\n        opcodes (List[Tuple[str, int, int, int, int]]): Opcodes from `diff` library.\n    \"\"\"\nself.job_name = None\nself.audio_url = None\nself.language = None\nself.type = type\nself.lists = lists\nself.differences = differences\nself.opcodes = opcodes\n</code></pre>"},{"location":"reference/transcribe/mispronunciation/#transcribe.mispronunciation.detect_mispronunciation","title":"<code>detect_mispronunciation(ground_truth, transcript, homophones=None)</code>","text":"<p>Detects if the pair of ground truth and transcript is considered as a mispronunciation.</p> <p>We define a mispronunciation to be either an addition (A) / substitution (S). Ignores deletion (D), 100% match (M) and single-word GT (X), returning <code>None</code>. Also handles homophones given a pre-defined list.</p> <p>Parameters:</p> Name Type Description Default <code>ground_truth</code> <code>List[str]</code> <p>List of ground truth words.</p> required <code>transcript</code> <code>List[str]</code> <p>List of transcript words.</p> required <code>homophones</code> <code>List[Set[str]]</code> <p>List of homophone families. Defaults                                    to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Mispronunciation</code> <code>Mispronunciation</code> <p>Object of mispronunciation present. Otherwise, <code>None</code>.</p>"},{"location":"reference/transcribe/mispronunciation/#transcribe.mispronunciation.detect_mispronunciation--examples","title":"Examples","text":"# Ground Truth Transcript Verdict 1 skel is a skeleton skel is a skeleton M 2 skel is a skeleton skel is not a skeleton A 3 skel is a skeleton skel is a zombie S 4 skel is a skeleton skel is not a zombie A &amp; S 5 skel is a skeleton skel is skeleton D 6 skel is a skeleton skel is zombie D 7 vain is a skeleton vein is a skeleton M 8 skel skel is a skeleton X"},{"location":"reference/transcribe/mispronunciation/#transcribe.mispronunciation.detect_mispronunciation--algorithm","title":"Algorithm","text":"<p>BASE CASES if:</p> <ul> <li>single-word ground truth</li> <li>empty transcript</li> <li>zero alignment</li> </ul> <p>MATCH if:</p> <ul> <li>both residues are empty (100% match)</li> </ul> <p>DELETION if:</p> <ul> <li>zero transcript residue, &gt;1 ground truth residue<ul> <li>all spoken transcripts are correct, but some words are missing</li> </ul> </li> <li>more residue in ground truth than in transcript<ul> <li>less strict condition than above</li> <li>may possibly contain substitution, but could be minimal</li> </ul> </li> </ul> <p>ADDITION if:</p> <ul> <li>zero ground truth residue, &gt;1 transcript residue<ul> <li>all words in ground truth are perfectly spoken, but additional words are present</li> </ul> </li> </ul> <p>SUBSTITUTION if:</p> <ul> <li>same amounts of residue, at exact same positions<ul> <li>strict form of substitution, only 1-1 changes per position</li> </ul> </li> </ul> <p>ADDITION &amp; SUBSTITUTION if:</p> <ul> <li>more residue in transcript than in ground truth<ul> <li>with at least 1 match</li> </ul> </li> </ul> Source code in <code>src/transcribe/mispronunciation.py</code> <pre><code>def detect_mispronunciation(\nground_truth: List[str], transcript: List[str], homophones: List[Set[str]] = None\n) -&gt; Mispronunciation:\n\"\"\"Detects if the pair of ground truth and transcript is considered as a\n    mispronunciation.\n    We define a mispronunciation to be either an addition (A) / substitution (S).\n    Ignores deletion (D), 100% match (M) and single-word GT (X), returning `None`.\n    Also handles homophones given a pre-defined list.\n    Args:\n        ground_truth (List[str]): List of ground truth words.\n        transcript (List[str]): List of transcript words.\n        homophones (List[Set[str]], optional): List of homophone families. Defaults\n                                               to None.\n    Returns:\n        Mispronunciation: Object of mispronunciation present. Otherwise, `None`.\n    Examples\n    -------------------------------------------------------------\n    | # | Ground Truth       | Transcript             | Verdict |\n    |:-:|--------------------|------------------------|:-------:|\n    | 1 | skel is a skeleton | skel is a skeleton     |    M    |\n    | 2 | skel is a skeleton | skel is not a skeleton |    A    |\n    | 3 | skel is a skeleton | skel is a zombie       |    S    |\n    | 4 | skel is a skeleton | skel is not a zombie   |  A &amp; S  |\n    | 5 | skel is a skeleton | skel is skeleton       |    D    |\n    | 6 | skel is a skeleton | skel is zombie         |    D    |\n    | 7 | vain is a skeleton | vein is a skeleton     |    M    |\n    | 8 | skel               | skel is a skeleton     |    X    |\n    Algorithm\n    ----------\n    BASE CASES if:\n    - single-word ground truth\n    - empty transcript\n    - zero alignment\n    MATCH if:\n    - both residues are empty (100% match)\n    DELETION if:\n    - zero transcript residue, &gt;1 ground truth residue\n        - all spoken transcripts are correct, but some words are missing\n    - more residue in ground truth than in transcript\n        - less strict condition than above\n        - may possibly contain substitution, but could be minimal\n    ADDITION if:\n    - zero ground truth residue, &gt;1 transcript residue\n        - all words in ground truth are perfectly spoken, but additional words are\n        present\n    SUBSTITUTION if:\n    - same amounts of residue, at exact same positions\n        - strict form of substitution, only 1-1 changes per position\n    ADDITION &amp; SUBSTITUTION if:\n    - more residue in transcript than in ground truth\n        - with at least 1 match\n    \"\"\"\nif homophones is None:\nhomophones = HOMOPHONES[\"en\"]\ntranscript = list(filter(remove_fillers, transcript))\nif len(ground_truth) == 1 or len(transcript) == 0:\nreturn None  # single word or filler-only transcript\ntsc_idx = set(range(len(transcript)))\ngt_idx = set(range(len(ground_truth)))\naligned_tsc, aligned_gt, opcodes = match_sequence(\ntranscript, ground_truth, homophones\n)\nif len(aligned_tsc) == 0 and len(aligned_gt) == 0:\nreturn None  # zero matches/alignments, pretty much random\ntsc_diff = tsc_idx.difference(aligned_tsc)\ngt_diff = gt_idx.difference(aligned_gt)\ntsc_diff_words = [transcript[idx] for idx in tsc_diff]\ngt_diff_words = [ground_truth[idx] for idx in gt_diff]\nmispronunciation = Mispronunciation(\nNone, (ground_truth, transcript), (gt_diff_words, tsc_diff_words), opcodes\n)\nif len(gt_diff) == 0 and len(tsc_diff) == 0:\nreturn None  # 100% match\nelif len(gt_diff) &gt; 0 and len(tsc_diff) == 0:\nreturn None  # deletion only\nelif len(gt_diff) == 0 and len(tsc_diff) &gt; 0:\nmispronunciation.type = MispronunciationType.ADDITION\nreturn mispronunciation  # addition only\nelif len(tsc_diff) == len(gt_diff) and tsc_diff == gt_diff:\nmispronunciation.type = MispronunciationType.SUBSTITUTION\nreturn mispronunciation  # strict substitution only\nelif len(tsc_diff) &gt;= len(gt_diff):\nmispronunciation.type = MispronunciationType.ADDITION_SUBSTITUTION\nreturn mispronunciation  # addition &amp; substitution\nelse:\n# in cases where there is less spoken words (transcript) compared to GT,\n# we assume that there is mostly deletion, although it may contain substitutions\n# we think, the transcript thus contain little to no information that may be\n# useful for training.\nreturn None\n</code></pre>"},{"location":"reference/transcribe/mispronunciation/#transcribe.mispronunciation.remove_fillers","title":"<code>remove_fillers(word)</code>","text":"<p>Manually checks if a word is a filler word</p> <p>Parameters:</p> Name Type Description Default <code>word</code> <code>str</code> <p>Any word (sequence of characters).</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p><code>True</code> if word is not a filler. <code>False</code> otherwise.</p> Source code in <code>src/transcribe/mispronunciation.py</code> <pre><code>def remove_fillers(word: str) -&gt; bool:\n\"\"\"Manually checks if a word is a filler word\n    Args:\n        word (str): Any word (sequence of characters).\n    Returns:\n        bool: `True` if word is not a filler. `False` otherwise.\n    \"\"\"\nfillers = (\"\", \"uh\", \"huh\", \"mm\", \"yeah\", \"mhm\", \"hmm\", \"hm\")\nreturn word not in fillers\n</code></pre>"},{"location":"reference/transcribe/s3_utils/","title":"AWS S3 Utilities","text":""},{"location":"reference/transcribe/s3_utils/#transcribe.s3_utils","title":"<code>transcribe.s3_utils</code>","text":""},{"location":"reference/transcribe/s3_utils/#transcribe.s3_utils.S3Client","title":"<code>S3Client</code>","text":"Source code in <code>src/transcribe/s3_utils.py</code> <pre><code>class S3Client:\ndef __init__(self, region_name=\"us-east-1\"):\nself.client = boto3.client(\"s3\", region_name=region_name)\nself.resource = boto3.resource(\"s3\", region_name=region_name)\ndef move_file(self, bucket: str, file: str, source: str, destination: str):\n\"\"\"Move `file` in `bucket` from `source` to `destination` folder\n        Args:\n            bucket (str): S3 bucket name.\n            file (str): Name of file to be moved (without full-path).\n            source (str): Source folder in S3 bucket.\n            destination (str): Destination folder in S3 bucket.\n        \"\"\"\ntry:\nself.resource.Object(bucket, f\"{destination}/{file}\").copy_from(\nCopySource=f\"{bucket}/{source}/{file}\"\n)\nself.resource.Object(bucket, f\"{source}/{file}\").delete()\nexcept Exception as exc:\nprint(\nf\"Failed to move file from {bucket}/{source}/{file} to\",\nf\"{bucket}/{destination}/{file}\",\n)\nprint(exc)\nelse:\nprint(\nf\"Moved file from {bucket}/{source}/{file} to\",\nf\"{bucket}/{destination}/{file}\",\n)\ndef copy_file(self, bucket: str, file: str, source: str, destination: str):\n\"\"\"Copy `file` in `bucket` from `source` to `destination` folder\n        Args:\n            bucket (str): S3 bucket name.\n            file (str): Name of file to be copied (without full-path).\n            source (str): Source folder in S3 bucket.\n            destination (str): Destination folder in S3 bucket.\n        \"\"\"\ntry:\nself.resource.Object(bucket, f\"{destination}/{file}\").copy_from(\nCopySource=f\"{bucket}/{source}/{file}\"\n)\nexcept Exception:\nprint(\nf\"Failed to copy file from {bucket}/{source}/{file} to\",\nf\"{bucket}/{destination}/{file}\",\n)\nelse:\nprint(\nf\"Copied file from {bucket}/{source}/{file} to\",\nf\"{bucket}/{destination}/{file}\",\n)\ndef get_object(self, bucket: str, key: str) -&gt; Any:\n\"\"\"Gets object from S3.\n        Args:\n            bucket (str): S3 bucket name.\n            key (str): Key to file in bucket.\n        Returns:\n            Any: S3 Object retrieved.\n        \"\"\"\ntry:\ns3_object = self.client.get_object(Bucket=bucket, Key=key)\nexcept Exception:\nreturn None\nelse:\nreturn s3_object\ndef put_object(self, json_object: str, bucket: str, key: str):\n\"\"\"Puts `json_object` (in str) to S3 bucket.\n        Args:\n            json_object (str): String representation of JSON object to put in S3.\n            bucket (str): S3 bucket name.\n            key (str): Key to file in bucket.\n        \"\"\"\ntry:\nself.client.put_object(Body=json.dumps(json_object), Bucket=bucket, Key=key)\nexcept Exception as exc:\nprint(exc)\ndef create_presigned_url(\nself, bucket_name: str, object_name: str, expiration: int = 3600\n) -&gt; Any:\n\"\"\"Generate a presigned URL to share an S3 object\n        Args:\n            bucket_name (str): Bucket name\n            object_name (str): Name of object/file\n            expiration (int, optional):\n                Time (seconds) for the presigned URL to remain valid.\n                Defaults to 3600.\n        Returns:\n            Any: Presigned URL as string. If error, returns `None`.\n        \"\"\"\ntry:\nresponse = self.client.generate_presigned_url(\n\"get_object\",\nParams={\"Bucket\": bucket_name, \"Key\": object_name},\nExpiresIn=expiration,\n)\nexcept ClientError as exc:\nprint(exc)\nreturn None\nreturn response\n</code></pre>"},{"location":"reference/transcribe/s3_utils/#transcribe.s3_utils.S3Client.copy_file","title":"<code>copy_file(bucket, file, source, destination)</code>","text":"<p>Copy <code>file</code> in <code>bucket</code> from <code>source</code> to <code>destination</code> folder</p> <p>Parameters:</p> Name Type Description Default <code>bucket</code> <code>str</code> <p>S3 bucket name.</p> required <code>file</code> <code>str</code> <p>Name of file to be copied (without full-path).</p> required <code>source</code> <code>str</code> <p>Source folder in S3 bucket.</p> required <code>destination</code> <code>str</code> <p>Destination folder in S3 bucket.</p> required Source code in <code>src/transcribe/s3_utils.py</code> <pre><code>def copy_file(self, bucket: str, file: str, source: str, destination: str):\n\"\"\"Copy `file` in `bucket` from `source` to `destination` folder\n    Args:\n        bucket (str): S3 bucket name.\n        file (str): Name of file to be copied (without full-path).\n        source (str): Source folder in S3 bucket.\n        destination (str): Destination folder in S3 bucket.\n    \"\"\"\ntry:\nself.resource.Object(bucket, f\"{destination}/{file}\").copy_from(\nCopySource=f\"{bucket}/{source}/{file}\"\n)\nexcept Exception:\nprint(\nf\"Failed to copy file from {bucket}/{source}/{file} to\",\nf\"{bucket}/{destination}/{file}\",\n)\nelse:\nprint(\nf\"Copied file from {bucket}/{source}/{file} to\",\nf\"{bucket}/{destination}/{file}\",\n)\n</code></pre>"},{"location":"reference/transcribe/s3_utils/#transcribe.s3_utils.S3Client.create_presigned_url","title":"<code>create_presigned_url(bucket_name, object_name, expiration=3600)</code>","text":"<p>Generate a presigned URL to share an S3 object</p> <p>Parameters:</p> Name Type Description Default <code>bucket_name</code> <code>str</code> <p>Bucket name</p> required <code>object_name</code> <code>str</code> <p>Name of object/file</p> required <code>expiration</code> <code>int</code> <p>Time (seconds) for the presigned URL to remain valid. Defaults to 3600.</p> <code>3600</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>Presigned URL as string. If error, returns <code>None</code>.</p> Source code in <code>src/transcribe/s3_utils.py</code> <pre><code>def create_presigned_url(\nself, bucket_name: str, object_name: str, expiration: int = 3600\n) -&gt; Any:\n\"\"\"Generate a presigned URL to share an S3 object\n    Args:\n        bucket_name (str): Bucket name\n        object_name (str): Name of object/file\n        expiration (int, optional):\n            Time (seconds) for the presigned URL to remain valid.\n            Defaults to 3600.\n    Returns:\n        Any: Presigned URL as string. If error, returns `None`.\n    \"\"\"\ntry:\nresponse = self.client.generate_presigned_url(\n\"get_object\",\nParams={\"Bucket\": bucket_name, \"Key\": object_name},\nExpiresIn=expiration,\n)\nexcept ClientError as exc:\nprint(exc)\nreturn None\nreturn response\n</code></pre>"},{"location":"reference/transcribe/s3_utils/#transcribe.s3_utils.S3Client.get_object","title":"<code>get_object(bucket, key)</code>","text":"<p>Gets object from S3.</p> <p>Parameters:</p> Name Type Description Default <code>bucket</code> <code>str</code> <p>S3 bucket name.</p> required <code>key</code> <code>str</code> <p>Key to file in bucket.</p> required <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>S3 Object retrieved.</p> Source code in <code>src/transcribe/s3_utils.py</code> <pre><code>def get_object(self, bucket: str, key: str) -&gt; Any:\n\"\"\"Gets object from S3.\n    Args:\n        bucket (str): S3 bucket name.\n        key (str): Key to file in bucket.\n    Returns:\n        Any: S3 Object retrieved.\n    \"\"\"\ntry:\ns3_object = self.client.get_object(Bucket=bucket, Key=key)\nexcept Exception:\nreturn None\nelse:\nreturn s3_object\n</code></pre>"},{"location":"reference/transcribe/s3_utils/#transcribe.s3_utils.S3Client.move_file","title":"<code>move_file(bucket, file, source, destination)</code>","text":"<p>Move <code>file</code> in <code>bucket</code> from <code>source</code> to <code>destination</code> folder</p> <p>Parameters:</p> Name Type Description Default <code>bucket</code> <code>str</code> <p>S3 bucket name.</p> required <code>file</code> <code>str</code> <p>Name of file to be moved (without full-path).</p> required <code>source</code> <code>str</code> <p>Source folder in S3 bucket.</p> required <code>destination</code> <code>str</code> <p>Destination folder in S3 bucket.</p> required Source code in <code>src/transcribe/s3_utils.py</code> <pre><code>def move_file(self, bucket: str, file: str, source: str, destination: str):\n\"\"\"Move `file` in `bucket` from `source` to `destination` folder\n    Args:\n        bucket (str): S3 bucket name.\n        file (str): Name of file to be moved (without full-path).\n        source (str): Source folder in S3 bucket.\n        destination (str): Destination folder in S3 bucket.\n    \"\"\"\ntry:\nself.resource.Object(bucket, f\"{destination}/{file}\").copy_from(\nCopySource=f\"{bucket}/{source}/{file}\"\n)\nself.resource.Object(bucket, f\"{source}/{file}\").delete()\nexcept Exception as exc:\nprint(\nf\"Failed to move file from {bucket}/{source}/{file} to\",\nf\"{bucket}/{destination}/{file}\",\n)\nprint(exc)\nelse:\nprint(\nf\"Moved file from {bucket}/{source}/{file} to\",\nf\"{bucket}/{destination}/{file}\",\n)\n</code></pre>"},{"location":"reference/transcribe/s3_utils/#transcribe.s3_utils.S3Client.put_object","title":"<code>put_object(json_object, bucket, key)</code>","text":"<p>Puts <code>json_object</code> (in str) to S3 bucket.</p> <p>Parameters:</p> Name Type Description Default <code>json_object</code> <code>str</code> <p>String representation of JSON object to put in S3.</p> required <code>bucket</code> <code>str</code> <p>S3 bucket name.</p> required <code>key</code> <code>str</code> <p>Key to file in bucket.</p> required Source code in <code>src/transcribe/s3_utils.py</code> <pre><code>def put_object(self, json_object: str, bucket: str, key: str):\n\"\"\"Puts `json_object` (in str) to S3 bucket.\n    Args:\n        json_object (str): String representation of JSON object to put in S3.\n        bucket (str): S3 bucket name.\n        key (str): Key to file in bucket.\n    \"\"\"\ntry:\nself.client.put_object(Body=json.dumps(json_object), Bucket=bucket, Key=key)\nexcept Exception as exc:\nprint(exc)\n</code></pre>"},{"location":"reference/transcribe/srt2txt/","title":"SRT2TXT","text":""},{"location":"reference/transcribe/srt2txt/#transcribe.srt2txt","title":"<code>transcribe.srt2txt</code>","text":""},{"location":"reference/transcribe/srt2txt/#transcribe.srt2txt.srt2txt","title":"<code>srt2txt(srt_string)</code>","text":"<p>Converts stream of srt subtitles to text format.</p> <p>Parameters:</p> Name Type Description Default <code>srt_string</code> <code>str</code> <p>String-representation of srt subtitles.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Cleaned text format of subtitles concatenated with space.</p> Source code in <code>src/transcribe/srt2txt.py</code> <pre><code>def srt2txt(srt_string: str) -&gt; str:\n\"\"\"Converts stream of srt subtitles to text format.\n    Args:\n        srt_string (str): String-representation of srt subtitles.\n    Returns:\n        str: Cleaned text format of subtitles concatenated with space.\n    \"\"\"\nsubs = pysrt.from_string(srt_string)\ntexts = [sub.text for sub in subs]\n# filter for empty strings\ntexts = list(filter(lambda text: len(text) &gt; 0, texts))\n# filter special tokens like [Music] and [Applause]\ntexts = list(filter(lambda text: text[0] != \"[\" and text[-1] != \"]\", texts))\ntexts = \" \".join(texts)\ntexts = texts.replace(\"\\n\", \" \")\nreturn texts\n</code></pre>"},{"location":"reference/transcribe/transcribe/","title":"Transcribe","text":""},{"location":"reference/transcribe/transcribe/#transcribe.transcribe","title":"<code>transcribe.transcribe</code>","text":""},{"location":"reference/transcribe/transcribe/#transcribe.transcribe.TranscribeClient","title":"<code>TranscribeClient</code>","text":"Source code in <code>src/transcribe/transcribe.py</code> <pre><code>class TranscribeClient:\ndef __init__(self, region_name=\"us-east-1\"):\nself.client = boto3.client(\"transcribe\", region_name=region_name)\ndef get_job(\nself, client: boto3.session.Session.client, job_name: str\n) -&gt; Dict[str, Any]:\n\"\"\"Check if current job already exists\n        Args:\n            client (boto3.session.Session.client): AWS Transcribe client from boto3.\n            job_name (str): Job name in AWS Transcribe.\n        Returns:\n            Dict[str, Any]:\n                JSON-formatted response from AWS Transcribe, `None` on failure.\n        \"\"\"\ntry:\nresponse = client.get_transcription_job(TranscriptionJobName=job_name)\nreturn response\nexcept ClientError:\nreturn None\ndef create_task(\nself, file_uri: str, job: Dict[str, Any]\n) -&gt; Tuple[TranscribeStatus, Dict[str, Any], Dict[str, Any]]:\n\"\"\"Creates a JSON-formatted task for Label Studio from AWS Transcribe output.\n        Args:\n            file_uri (str): URI to audio file in S3 to be Transcribed.\n            job (Dict[str, Any]): JSON-formatted response from AWS Transcribe.\n        Returns:\n            Tuple[TranscribeStatus, Dict[str, Any], Dict[str, Any]]:\n                Tuple consisting of (1) status of AWS Transcribe job, (2) AWS Transcribe\n                results and (3) JSON-formatted task for Label Studio\n        \"\"\"\ntry:\ndownload_uri = job[\"TranscriptionJob\"][\"Transcript\"][\"TranscriptFileUri\"]\nresults = requests.get(download_uri).json()[\"results\"]\ntranscriptions = [r[\"transcript\"] for r in results[\"transcripts\"]]\n# confidence score for the entire phrase is\n# a mean of confidence for individual words\nconfidence = sum(\nfloat(item[\"alternatives\"][0][\"confidence\"])\nfor item in results[\"items\"]\nif item[\"type\"] == \"pronunciation\"\n) / sum(1.0 for item in results[\"items\"] if item[\"type\"] == \"pronunciation\")\nexcept ZeroDivisionError:\nconfidence = 0.0\nexcept Exception as exc:\nprint(f\"Error: {exc}\")\nreturn (\nTranscribeStatus.FAILED,\nNone,\n{\n\"data\": {\"audio\": file_uri},\n\"predictions\": [\n{\n\"model_version\": \"amazon_transcribe\",\n\"result\": [\n{\n\"from_name\": \"transcription\",\n\"to_name\": \"audio\",\n\"type\": \"textarea\",\n\"value\": {\"text\": [\"\"]},\n},\n],\n}\n],\n},\n)\n# if no exceptions occur or if confidence is set to 0.0\nreturn (\nTranscribeStatus.SUCCESS,\nresults,\n{\n\"data\": {\"audio\": file_uri},\n\"predictions\": [\n{\n\"model_version\": \"amazon_transcribe\",\n\"result\": [\n{\n\"from_name\": \"transcription\",\n\"to_name\": \"audio\",\n\"type\": \"textarea\",\n\"value\": {\"text\": transcriptions},\n},\n],\n\"score\": confidence,\n}\n],\n},\n)\ndef transcribe_file(\nself,\njob_name: str,\nfile_uri: str,\nmedia_format: str = \"mp4\",\nlanguage_code: str = \"en-US\",\n) -&gt; Tuple[TranscribeStatus, Dict[str, Any]]:\n\"\"\"Transcribes audio file with AWS Transcribe.\n        Args:\n            job_name (str): AWS Transcribe job name.\n            file_uri (str): URI to audio file in S3 to be Transcribed.\n            media_format (str, optional): Format of audio file. Defaults to \"mp4\".\n            language_code (str, optional): AWS Transcribe language code of audio.\n                                        Defaults to \"en-US\".\n        Returns:\n            Tuple[TranscribeStatus, Dict[str, Any]]:\n                Tuple consisting of:\n                    (1) status of AWS Transcribe job and\n                    (2) JSON-formatted\n                task for Label Studio\n        \"\"\"\njob = self.get_job(self.client, job_name)\nif job:\nprint(f\"Transcription job {job_name} already exists.\")\nreturn self.create_task(file_uri, job)\n# begin transcription job\nprint(f\"Start transcription job {job_name}\")\nself.client.start_transcription_job(\nTranscriptionJobName=job_name,\nMedia={\"MediaFileUri\": file_uri},\nMediaFormat=media_format,\nLanguageCode=language_code,\n)\n# might be risky, but this relies on Lambda's timeout\nwhile True:\njob = self.client.get_transcription_job(TranscriptionJobName=job_name)\njob_status = job[\"TranscriptionJob\"][\"TranscriptionJobStatus\"]\nif job_status in [\"COMPLETED\", \"FAILED\"]:\nprint(f\"Job {job_name} is {job_status}.\")\n# if transcription job completes or fails, create Label Studio\n# JSON-formatted task accordingly\nreturn self.create_task(file_uri, job)\nelif job_status == \"IN_PROGRESS\":\n# otherwise, if the transcription is still in progress, keep it running\nprint(f\"Waiting for {job_name}. Current status is {job_status}.\")\n# give a 10 second timeout\ntime.sleep(10)\n</code></pre>"},{"location":"reference/transcribe/transcribe/#transcribe.transcribe.TranscribeClient.create_task","title":"<code>create_task(file_uri, job)</code>","text":"<p>Creates a JSON-formatted task for Label Studio from AWS Transcribe output.</p> <p>Parameters:</p> Name Type Description Default <code>file_uri</code> <code>str</code> <p>URI to audio file in S3 to be Transcribed.</p> required <code>job</code> <code>Dict[str, Any]</code> <p>JSON-formatted response from AWS Transcribe.</p> required <p>Returns:</p> Type Description <code>Tuple[TranscribeStatus, Dict[str, Any], Dict[str, Any]]</code> <p>Tuple[TranscribeStatus, Dict[str, Any], Dict[str, Any]]: Tuple consisting of (1) status of AWS Transcribe job, (2) AWS Transcribe results and (3) JSON-formatted task for Label Studio</p> Source code in <code>src/transcribe/transcribe.py</code> <pre><code>def create_task(\nself, file_uri: str, job: Dict[str, Any]\n) -&gt; Tuple[TranscribeStatus, Dict[str, Any], Dict[str, Any]]:\n\"\"\"Creates a JSON-formatted task for Label Studio from AWS Transcribe output.\n    Args:\n        file_uri (str): URI to audio file in S3 to be Transcribed.\n        job (Dict[str, Any]): JSON-formatted response from AWS Transcribe.\n    Returns:\n        Tuple[TranscribeStatus, Dict[str, Any], Dict[str, Any]]:\n            Tuple consisting of (1) status of AWS Transcribe job, (2) AWS Transcribe\n            results and (3) JSON-formatted task for Label Studio\n    \"\"\"\ntry:\ndownload_uri = job[\"TranscriptionJob\"][\"Transcript\"][\"TranscriptFileUri\"]\nresults = requests.get(download_uri).json()[\"results\"]\ntranscriptions = [r[\"transcript\"] for r in results[\"transcripts\"]]\n# confidence score for the entire phrase is\n# a mean of confidence for individual words\nconfidence = sum(\nfloat(item[\"alternatives\"][0][\"confidence\"])\nfor item in results[\"items\"]\nif item[\"type\"] == \"pronunciation\"\n) / sum(1.0 for item in results[\"items\"] if item[\"type\"] == \"pronunciation\")\nexcept ZeroDivisionError:\nconfidence = 0.0\nexcept Exception as exc:\nprint(f\"Error: {exc}\")\nreturn (\nTranscribeStatus.FAILED,\nNone,\n{\n\"data\": {\"audio\": file_uri},\n\"predictions\": [\n{\n\"model_version\": \"amazon_transcribe\",\n\"result\": [\n{\n\"from_name\": \"transcription\",\n\"to_name\": \"audio\",\n\"type\": \"textarea\",\n\"value\": {\"text\": [\"\"]},\n},\n],\n}\n],\n},\n)\n# if no exceptions occur or if confidence is set to 0.0\nreturn (\nTranscribeStatus.SUCCESS,\nresults,\n{\n\"data\": {\"audio\": file_uri},\n\"predictions\": [\n{\n\"model_version\": \"amazon_transcribe\",\n\"result\": [\n{\n\"from_name\": \"transcription\",\n\"to_name\": \"audio\",\n\"type\": \"textarea\",\n\"value\": {\"text\": transcriptions},\n},\n],\n\"score\": confidence,\n}\n],\n},\n)\n</code></pre>"},{"location":"reference/transcribe/transcribe/#transcribe.transcribe.TranscribeClient.get_job","title":"<code>get_job(client, job_name)</code>","text":"<p>Check if current job already exists</p> <p>Parameters:</p> Name Type Description Default <code>client</code> <code>boto3.session.Session.client</code> <p>AWS Transcribe client from boto3.</p> required <code>job_name</code> <code>str</code> <p>Job name in AWS Transcribe.</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str, Any]: JSON-formatted response from AWS Transcribe, <code>None</code> on failure.</p> Source code in <code>src/transcribe/transcribe.py</code> <pre><code>def get_job(\nself, client: boto3.session.Session.client, job_name: str\n) -&gt; Dict[str, Any]:\n\"\"\"Check if current job already exists\n    Args:\n        client (boto3.session.Session.client): AWS Transcribe client from boto3.\n        job_name (str): Job name in AWS Transcribe.\n    Returns:\n        Dict[str, Any]:\n            JSON-formatted response from AWS Transcribe, `None` on failure.\n    \"\"\"\ntry:\nresponse = client.get_transcription_job(TranscriptionJobName=job_name)\nreturn response\nexcept ClientError:\nreturn None\n</code></pre>"},{"location":"reference/transcribe/transcribe/#transcribe.transcribe.TranscribeClient.transcribe_file","title":"<code>transcribe_file(job_name, file_uri, media_format='mp4', language_code='en-US')</code>","text":"<p>Transcribes audio file with AWS Transcribe.</p> <p>Parameters:</p> Name Type Description Default <code>job_name</code> <code>str</code> <p>AWS Transcribe job name.</p> required <code>file_uri</code> <code>str</code> <p>URI to audio file in S3 to be Transcribed.</p> required <code>media_format</code> <code>str</code> <p>Format of audio file. Defaults to \"mp4\".</p> <code>'mp4'</code> <code>language_code</code> <code>str</code> <p>AWS Transcribe language code of audio.                         Defaults to \"en-US\".</p> <code>'en-US'</code> <p>Returns:</p> Type Description <code>Tuple[TranscribeStatus, Dict[str, Any]]</code> <p>Tuple[TranscribeStatus, Dict[str, Any]]: Tuple consisting of:     (1) status of AWS Transcribe job and     (2) JSON-formatted task for Label Studio</p> Source code in <code>src/transcribe/transcribe.py</code> <pre><code>def transcribe_file(\nself,\njob_name: str,\nfile_uri: str,\nmedia_format: str = \"mp4\",\nlanguage_code: str = \"en-US\",\n) -&gt; Tuple[TranscribeStatus, Dict[str, Any]]:\n\"\"\"Transcribes audio file with AWS Transcribe.\n    Args:\n        job_name (str): AWS Transcribe job name.\n        file_uri (str): URI to audio file in S3 to be Transcribed.\n        media_format (str, optional): Format of audio file. Defaults to \"mp4\".\n        language_code (str, optional): AWS Transcribe language code of audio.\n                                    Defaults to \"en-US\".\n    Returns:\n        Tuple[TranscribeStatus, Dict[str, Any]]:\n            Tuple consisting of:\n                (1) status of AWS Transcribe job and\n                (2) JSON-formatted\n            task for Label Studio\n    \"\"\"\njob = self.get_job(self.client, job_name)\nif job:\nprint(f\"Transcription job {job_name} already exists.\")\nreturn self.create_task(file_uri, job)\n# begin transcription job\nprint(f\"Start transcription job {job_name}\")\nself.client.start_transcription_job(\nTranscriptionJobName=job_name,\nMedia={\"MediaFileUri\": file_uri},\nMediaFormat=media_format,\nLanguageCode=language_code,\n)\n# might be risky, but this relies on Lambda's timeout\nwhile True:\njob = self.client.get_transcription_job(TranscriptionJobName=job_name)\njob_status = job[\"TranscriptionJob\"][\"TranscriptionJobStatus\"]\nif job_status in [\"COMPLETED\", \"FAILED\"]:\nprint(f\"Job {job_name} is {job_status}.\")\n# if transcription job completes or fails, create Label Studio\n# JSON-formatted task accordingly\nreturn self.create_task(file_uri, job)\nelif job_status == \"IN_PROGRESS\":\n# otherwise, if the transcription is still in progress, keep it running\nprint(f\"Waiting for {job_name}. Current status is {job_status}.\")\n# give a 10 second timeout\ntime.sleep(10)\n</code></pre>"}]}