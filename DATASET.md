# Dataset Card for Bookbot Speech

## Dataset Summary

The Bookbot Speech dataset consists of WAV and corresponding text file. The data is grouped based on the language and the user's region (country) that can help improve the accuracy of speech recognition engines.

## Intended Use

The dataset is mainly intended to be used to train speech recognition models, particularly for children's speech. Other use cases might include speech classification (e.g. accents/location).

## Languages

English, Indonesian

## Dataset Structure

### Data Fields

| Field        | Description                                                     |
| ------------ | --------------------------------------------------------------- |
| `Job Name`   | Hashed ID of the audio recording.                               |
| `Audio`      | Training-ready audio file, in WAV format, 16 bit, 24 kHz, Mono. |
| `Language`   | Language-Region. E.g. `en-us`, `en-au`, `id-id`.                |
| `Transcript` | Transcript of the spoken speech.                                |

### Data Splits

The data has not been split into different subsets. The end user is free to decide how to split the dataset. However, we normally would group them on a per-speaker basis. That is, speakers in the training set is usually not found in the valid/test sets to ensure the generalizability of our model during evaluation.

## Dataset Creation

### Curation Rationale

This dataset is curated due to the lack of children's data for speech recognition model training purposes.

### Source Data

Early users of the Bookbot app during our initial app testing session, conducted across multiple schools.

### Annotations

Our entire labeling pipeline is fully automated. Ground truth from book texts that our users are reading is compared with transcripts generated by AWS Transcribe. They are then aligned and overlaps between them are taken to be exported as instances of this data. There are no humans within our labeling loop.

